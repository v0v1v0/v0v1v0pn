<div class="container">

<table style="width: 100%;"><tr>
<td>viewers</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Text Document Viewers</h2>

<h3>Description</h3>

<p>Provide suitable “views” of the text contained in text
documents.
</p>


<h3>Usage</h3>

<pre><code class="language-R">words(x, ...)
sents(x, ...)
paras(x, ...)
tagged_words(x, ...)
tagged_sents(x, ...)
tagged_paras(x, ...)
chunked_sents(x, ...)
parsed_sents(x, ...)
parsed_paras(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>a text document object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Methods for extracting POS tagged word tokens (i.e., for generics
<code>tagged_words()</code>, <code>tagged_sents()</code> and
<code>tagged_paras()</code>) can optionally provide a mechanism for mapping
the POS tags via a <code>map</code> argument.  This can give a function, a
named character vector (with names and elements the tags to map from
and to, respectively), or a named list of such named character
vectors, with names corresponding to POS tagsets (see
<code>Universal_POS_tags_map</code> for an example).  If a list, the
map used will be the element with name matching the POS tagset used
(this information is typically determined from the text document
metadata; see the the help pages for text document extension classes
implementing this mechanism for details).
</p>
<p>Text document classes may provide support for representing both
(syntactic) words (for which annotations can be provided) and
orthographic (word) tokens, e.g., in Spanish <em>dámelo = da me lo</em>.
For these, <code>words()</code> gives the syntactic word tokens, and
<code>otoks()</code> the orthographic word tokens.  This is currently
supported for CoNNL-U text documents (see
<a href="https://universaldependencies.org/format.html">https://universaldependencies.org/format.html</a> for more
information) and annotated plain
text documents (via <code>word</code> features as used for example for some
Stanford CoreNLP annotator pipelines provided by package
<span class="pkg">StanfordCoreNLP</span> available from the repository at
<a href="https://datacube.wu.ac.at">https://datacube.wu.ac.at</a>).
</p>
<p>In addition to methods for the text document classes provided by
package <span class="pkg">NLP</span> itself, (see TextDocument), package <span class="pkg">NLP</span>
also provides word tokens and POS tagged word tokens for the results
of
<code>udpipe_annotate()</code>
from package <a href="https://CRAN.R-project.org/package=udpipe"><span class="pkg">udpipe</span></a>,
<code>spacy_parse()</code>
from package <a href="https://CRAN.R-project.org/package=spacyr"><span class="pkg">spacyr</span></a>,
and
<code>cnlp_annotate()</code>
from package <a href="https://CRAN.R-project.org/package=cleanNLP"><span class="pkg">cleanNLP</span></a>.
</p>


<h3>Value</h3>

<p>For <code>words()</code>, a character vector with the word tokens in the
document.
</p>
<p>For <code>sents()</code>, a list of character vectors with the word tokens
in the sentences.
</p>
<p>For <code>paras()</code>, a list of lists of character vectors with the word
tokens in the sentences, grouped according to the paragraphs.
</p>
<p>For <code>tagged_words()</code>, a character vector with the POS tagged word
tokens in the document (i.e., the word tokens and their POS tags,
separated by ‘<span class="samp">⁠/⁠</span>’).
</p>
<p>For <code>tagged_sents()</code>, a list of character vectors with the POS
tagged word tokens in the sentences.
</p>
<p>For <code>tagged_paras()</code>, a list of lists of character vectors with
the POS tagged word tokens in the sentences, grouped according to the
paragraphs.
</p>
<p>For <code>chunked_sents()</code>, a list of (flat) <code>Tree</code>
objects giving the chunk trees for the sentences in the document.
</p>
<p>For <code>parsed_sents()</code>, a list of <code>Tree</code>
objects giving the parse trees for the sentences in the document.
</p>
<p>For <code>parsed_paras()</code>, a list of lists of <code>Tree</code>
objects giving the parse trees for the sentences in the document,
grouped according to the paragraphs in the document.
</p>
<p>For <code>otoks()</code>, a character vector with the orthographic word
tokens in the document.
</p>


<h3>See Also</h3>

<p><code>TextDocument</code> for basic information on the text document
infrastructure employed by package <span class="pkg">NLP</span>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Example from &lt;https://universaldependencies.org/format.html&gt;:
d &lt;- CoNLLUTextDocument(system.file("texts", "spanish.conllu",
                                    package = "NLP"))
content(d)
## To extract the syntactic words:
words(d)
## To extract the orthographic word tokens:
otoks(d)
</code></pre>


</div>