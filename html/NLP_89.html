<div class="container">

<table style="width: 100%;"><tr>
<td>TaggedTextDocument</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>POS-Tagged Word Text Documents</h2>

<h3>Description</h3>

<p>Create text documents from files containing POS-tagged words.
</p>


<h3>Usage</h3>

<pre><code class="language-R">TaggedTextDocument(con, encoding = "unknown",
                   word_tokenizer = whitespace_tokenizer,
                   sent_tokenizer = Regexp_Tokenizer("\n", invert = TRUE),
                   para_tokenizer = blankline_tokenizer,
                   sep = "/",
                   meta = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>con</code></td>
<td>
<p>a connection object or a character string.
See <code>readLines()</code> for details.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>encoding</code></td>
<td>
<p>encoding to be assumed for input strings.
See <code>readLines()</code> for details.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>word_tokenizer</code></td>
<td>
<p>a function for obtaining the word token spans.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sent_tokenizer</code></td>
<td>
<p>a function for obtaining the sentence token
spans.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>para_tokenizer</code></td>
<td>
<p>a function for obtaining the paragraph token
spans, or <code>NULL</code> in which case no paragraph tokenization is
performed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sep</code></td>
<td>
<p>the character string separating the word tokens and their
POS tags.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>meta</code></td>
<td>
<p>a named or empty list of document metadata tag-value
pairs.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>TaggedTextDocument()</code> creates documents representing natural
language text as suitable collections of POS-tagged words, based on
using <code>readLines()</code> to read text lines from connections
providing such collections.
</p>
<p>The text read is split into paragraph, sentence and tagged word tokens
using the span tokenizers specified by arguments
<code>para_tokenizer</code>, <code>sent_tokenizer</code> and
<code>word_tokenizer</code>.  By default, paragraphs are assumed to be
separated by blank lines, sentences by newlines and tagged word tokens
by whitespace.  Finally, word tokens and their POS tags are obtained
by splitting the tagged word tokens according to <code>sep</code>.  From
this, a suitable representation of the provided collection of
POS-tagged words is obtained, and returned as a tagged text document
object inheriting from classes <code>"TaggedTextDocument"</code> and
<code>"TextDocument"</code>.
</p>
<p>There are methods for generics
<code>words()</code>,
<code>sents()</code>,
<code>paras()</code>,
<code>tagged_words()</code>,
<code>tagged_sents()</code>, and
<code>tagged_paras()</code>
(as well as <code>as.character()</code>)
and class <code>"TaggedTextDocument"</code>,
which should be used to access the text in such text document
objects.
</p>
<p>The methods for generics
<code>tagged_words()</code>, 
<code>tagged_sents()</code> and
<code>tagged_paras()</code>
provide a mechanism for mapping POS tags via the <code>map</code> argument,
see section <b>Details</b> in the help page for
<code>tagged_words()</code> for more information.
The POS tagset used will be inferred from the <code>POS_tagset</code>
metadata element of the CoNLL-style text document.
</p>


<h3>Value</h3>

<p>A tagged text document object inheriting from
<code>"TaggedTextDocument"</code> and <code>"TextDocument"</code>.
</p>


<h3>See Also</h3>

<p><a href="https://www.nltk.org/nltk_data/packages/corpora/brown.zip">https://www.nltk.org/nltk_data/packages/corpora/brown.zip</a>
which provides the W. N. Francis and H. Kucera Brown tagged word
corpus as an archive of files which can be read in using
<code>TaggedTextDocument()</code>.
</p>
<p>Package <span class="pkg">tm.corpus.Brown</span> available from the repository at
<a href="https://datacube.wu.ac.at">https://datacube.wu.ac.at</a> conveniently provides this corpus
as a <span class="pkg">tm</span> VCorpus of tagged text documents.
</p>


</div>