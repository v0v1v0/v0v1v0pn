<div class="container">

<table style="width: 100%;"><tr>
<td>StanfordCoreNLP_Pipeline</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Stanford <code>CoreNLP</code> annotator pipeline</h2>

<h3>Description</h3>

<p>Create a Stanford <code>CoreNLP</code> annotator pipeline.
</p>


<h3>Usage</h3>

<pre><code class="language-R">StanfordCoreNLP_Pipeline(annotators = c("pos", "lemma"),
  language = "en", control = list(), port = 9000L,
  host = "localhost")
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>annotators</code></td>
<td>
<p>a character string specifying the annotators to be used in addition
to ‘ssplit’ (sentence token annotation) and ‘tokenize’
(word token annotations), with elements
<code>"pos"</code> (POS tagging),
<code>"lemma"</code> (lemmatizing),
<code>"ner"</code> (named entity recognition),
<code>"regexner"</code> (rule-based named entity recognition over token
sequences using Java regular expressions),
<code>"parse"</code> (constituency parsing),
<code>"depparse"</code> (dependency parsing),
<code>"sentiment"</code> (sentiment analysis),
<code>"coref"</code> (coference resolution),
<code>"dcoref"</code> (deterministic coference resolution),
<code>"cleanxml"</code> (clean XML tags),
or
<code>"relation"</code> (relation extraction),
or unique abbreviations thereof.
Ignored for languages other than English.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>language</code></td>
<td>
<p>a character string giving the ISO-639 code of the
language being processed by the annotator pipeline.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>control</code></td>
<td>
<p>a named or empty (default) list vector with annotator control
options, with the names giving the option names.  See
<a href="https://stanfordnlp.github.io/CoreNLP/annotators.html">https://stanfordnlp.github.io/CoreNLP/annotators.html</a> for
available control options.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>port</code></td>
<td>
<p>an integer giving the port (default is <code>9000L</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>host</code></td>
<td>
<p>a character string giving the hostname of the server.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>An <code>Annotator</code> object providing the annotator pipeline.
</p>


<h3>Note</h3>

<p>See <a href="https://stanfordnlp.github.io/CoreNLP/#citing-stanford-corenlp-in-papers">https://stanfordnlp.github.io/CoreNLP/#citing-stanford-corenlp-in-papers</a>
for information on citing Stanford CoreNLP.
</p>
<p>Using the parse annotator requires considerable amounts of (Java)
memory.  The Stanford CoreNLP documentation suggests starting the JVM
with at least 3GB of memory on 64-bit systems (and in fact, not using
32-bit systems), and hence have the JVM started with <span class="option">-Xmx3g</span>
unless option <code>java.parameters</code> is set to something non-empty
(hence, this option should be set appropriately to accommodate
different memory requirements or constraints).
</p>
<p>Using the coreference annotators nowadays requires even more (Java)
memory.  The Stanford CoreNLP documentation suggests starting the JVM
with at least 5GB of memory; we find 4GB sufficient.  Hence, to use
these annotators one needs to set option <code>java.parameters</code> as
appropriate before starting the JVM.
</p>


<h3>See Also</h3>

<p><a href="https://stanfordnlp.github.io/CoreNLP/">https://stanfordnlp.github.io/CoreNLP/</a> for more 
information about the Stanford CoreNLP tools.
</p>


<h3>Examples</h3>

<pre><code class="language-R">require("NLP")
s &lt;- as.String(paste("Stanford University is located in California.",
                     "It is a great university."))
s

## Annotators: ssplit, tokenize:
if ( ping_nlp_client() == "pong" ) {
p &lt;- StanfordCoreNLP_Pipeline(NULL)
a &lt;- p(s)
a

## Annotators: ssplit, tokenize, pos, lemma (default):
p &lt;- StanfordCoreNLP_Pipeline()
a &lt;- p(s)
a

## Equivalently:
annotate(s, p)

## Annotators: ssplit, tokenize, parse:
p &lt;- StanfordCoreNLP_Pipeline("parse")
a &lt;- p(s)
a

## Respective formatted parse trees using Penn Treebank notation
## (see &lt;https://catalog.ldc.upenn.edu/docs/LDC95T7/cl93.html&gt;):
ptexts &lt;- sapply(subset(a, type == "sentence")$features, `[[`, "parse")
ptexts

## Read into NLP Tree objects.
ptrees &lt;- lapply(ptexts, Tree_parse)
ptrees

## Basic dependencies:
depends &lt;- lapply(subset(a, type == "sentence")$features, `[[`,
                  "basic-dependencies")
depends
## Note that the non-zero ids (gid for governor and did for dependent)
## refer to word token positions within the respective sentences, and
## not the ids of these token in the annotation: these can easily be
## matched using the sentence constituents features:
lapply(subset(a, type == "sentence")$features, `[[`, "constituents")

## (Similarly for sentence ids used in dcoref document features.)

## Note also that the dependencies are returned as a data frame 
## inheriting from class "Stanford_typed_dependencies" which has print
## and format methods for obtaining the usual formatting.
depends[[1L]]
## Use as.data.frame() to obtain strip this class:
as.data.frame(depends[[1L]])
}
</code></pre>


</div>