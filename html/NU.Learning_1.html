<div class="container">

<table style="width: 100%;"><tr>
<td>NU.Learning-package</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>NU.Learning: Nonparametric and Unsupervised Adjustment for Bias and Confounding</h2>

<h3>Description</h3>

<p>NU.Learning forms Local Treatment Differences (LTDs) or Local Rank Correlations
(LRCs) within Clusters of experimental units (patients, etc.) who have been relatively well-matched
on their baseline X-confounder characteristics.  The resulting distribution of LTD/LRC effect-size
estimates can be interpreted much like a Bayesian posterior. Yet these distributions have been
formed, via Nonparametric and Unsupervised Preprocessing, in purely Objective Ways.
</p>


<h3>Details</h3>


<table>
<tr>
<td style="text-align: left;">
  Package: </td>
<td style="text-align: left;"> NU.Learning</td>
</tr>
<tr>
<td style="text-align: left;">
  Type: </td>
<td style="text-align: left;"> Package</td>
</tr>
<tr>
<td style="text-align: left;">
  Version: </td>
<td style="text-align: left;"> 1.5</td>
</tr>
<tr>
<td style="text-align: left;">
  Date: </td>
<td style="text-align: left;"> 2023-09-15</td>
</tr>
<tr>
<td style="text-align: left;">
  License: </td>
<td style="text-align: left;"> GPL-2</td>
</tr>
<tr>
<td style="text-align: left;">
  </td>
</tr>
</table>
<p>UNSUPERVISED LOCAL TREATMENT DIFFERENCES or LOCAL RANK CORRELATIONS:
</p>
<p>Multiple calls to ltdagg(K) or lrcagg(K) for varying numbers of clusters, K, are typically
made after first invoking NUcluster() to hierarchically cluster patients in X-space and
invoking NUsetup() to specify a numeric y-Outcome variable and a numeric treatment choice
or exposure level measure, trex. 
</p>
<p>UNSUPERVISED INSTRUMENTAL VARIABLES = LOCAL AVERAGE y-OUTCOME EFFECTS:
</p>
<p>An OBSERVED Propensity Score (PS) is defined here to be either (i) the local (within-cluster)
fraction of experimental units (patients) receiving trex==1 (new) rather than trex==0 (control)
or else (ii) a measure of "relative exposure" when the numeric trex measure has (many) more
than 2 observed levels. Multiple calls to ivadj(K) for varying numbers of clusters, K, then
yield alternative scatters of Local Average Outcomes (LAOs) for Clusters when plotted against
their PS estimates and, thus, different possible linear fits or smooth.splines() yielding
potentially different inferences about across-cluster Treatment or Exposure Effects.
</p>
<p>CONFIRMATION and SENSITIVITY ANALYSES of LOCAL EFFECT-SIZE DISTRIBUTIONS:
</p>
<p>For a given value of K = Number of Clusters requested, the output object from ltdagg(K) or
lrcagg(K) can be input to confirm() to use (nonparametric) permutation theory to display 
visual evidence (empirical CDF comparisons) concerning the Question: "Does x-matching Truly
Matter?" The NULL hypothesis here is that the x-Covariates used in Clustering / Matching of
Experimental Units are actually IGNORABLE. Evidence against this hypothesis is provided when
the observed LOCAL Effect-Size Distribution clearly deviates from the purely RANDOM, NULL
distribution computed (to any desired precision) by randomly PERMUTING cluster ID labels
across experimental units. Furthermore, the statistical significance of differences between
the observed and random NULL distributions can be estimated using KSperm(), which simulates
the random permutation distribution of the Kolmogorov-Smirnov D-statistic when many tied
values occur in both distributions being compared. Finally, the NUcompare() function helps
users of NU.Learning decide which Number of Clusters, K, optimizes Variance-Bias trade-offs.
Larger values of K tend to yield smaller clusters with better matches and, thus, potentially
reduced BIAS. On the other hand, smaller values of K usually yield local effect-size
estimates with much lower Variability (higher Precision).
</p>
<p>"Most-Like-Me" HISTOGRAMS for DOCTOR-PATIENT discussions of PERSONALIZED MEDICINE:
</p>
<p>For a specified vector, xvec, of numerical values of the X-confounder variables used in the
current CLUSTERING of eUnits, display histograms of observed LTD or LRC effect-sizes for
(i) all available patients and (ii) for the specified number, NN, of "Nearest-Neighbors" in
X-confounder space of the TARGET eUnit ...i.e. xvec defines "Me".
</p>


<h3>Author(s)</h3>

<p>Bob Obenchain &lt;wizbob@att.net&gt;</p>


<h3>References</h3>

 
<p>McClellan M, McNeil BJ, Newhouse JP. (1994) Does More Intensive Treatment of
Myocardial Infarction in the Elderly Reduce Mortality?: Analysis Using Instrumental
Variables. <em>JAMA</em> <b>272</b>: 859-866.  
</p>
<p>Obenchain RL. (2010) The Local Control Approach using JMP. Chapter 7 of
<b>Analysis of Observational Health Care Data using SAS</b>, <em>Cary, NC:SAS Press</em>,
pages 151-192. 
</p>
<p>Obenchain RL, Young SS. (2013) Advancing Statistical Thinking in Observational Health
Care Research. <em>J. Stat. Theory and Practice</em>, <b>7</b>: 456-469,
<a href="https://doi.org/10.1080/15598608.2013.772821">doi:10.1080/15598608.2013.772821</a>.
</p>
<p>Lopiano KK, Obenchain RL, Young SS. (2014) Fair treatment comparisons in observational
research. <em>Statistical Analysis and Data Mining</em>, <b>7</b>: 376-384,
<a href="https://doi.org/10.1002/sam.11235">doi:10.1002/sam.11235</a>.
</p>
<p>Obenchain RL. NU.Learning-vignette. (2023) <b>NU.Learning_in_R.pdf</b>
http://localcontrolstatistics.org 
</p>
<p>Rosenbaum PR, Rubin RB. (1983) The Central Role of the Propensity Score
in Observational Studies for Causal Effects. <em>Biometrika</em> <b>70</b>:
41-55.
</p>
<p>Rosenbaum PR, Rubin RB. (1984) Reducing Bias in Observational Studies Using
Subclassification on a Propensity Score. <em>JASA</em> <b>79</b>: 516-524.
</p>
<p>Rubin DB. (1980) Bias reduction using Mahalanobis metric matching.
<em>Biometrics</em> <b>36</b>: 293-298.
</p>
<p>Stuart EA. (2010) Matching Methods for Causal Inference: A Review and a Look Forward.
<em>Statistical Science</em> <b>25</b>: 1-21.
</p>


</div>