<div class="container">

<table style="width: 100%;"><tr>
<td>NUcompare</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Display NU Sensitivity Graphic for help in choice of K = Number of Clusters</h2>

<h3>Description</h3>

<p>This function displays Box-Whisker diagrams that compare Treatment Effect-Size
distributions for different values of K = Number of Clusters requested in X-covariate space.
After an initial call to NUsetup(), the analyst typically makes multiple calls to either
ltdagg() or lrcagg() for different values of K.  The analyst then invokes NUcompare() to
see how choice of K changes the location, spread and/or skewness of the distribution of
Treatment Effect-Size estimates across Clusters. Variance-Bias trade-offs occur as K
increases; large values of K may reduce Bias, but they definitely inflate the Variance of
LTD and LRC distributions.</p>


<h3>Usage</h3>

<pre><code class="language-R">  NUcompare(envir)
</code></pre>


<h3>Arguments</h3>

<table><tr style="vertical-align: top;">
<td><code>envir</code></td>
<td>
<p>R environment output by an earlier call to NUsetup().</p>
</td>
</tr></table>
<h3>Details</h3>

<p>The third phase of NU.Learning is called EXPLORE and uses graphical
Sensitivity Analyses to show how Treatment Effect-Size distributions change with choice
of NU parameter settings. Choice of K = Number of Clusters requested is guided, primarily,
by NUcompare() graphics. Equally important are the analyst's choices of (i) which [and how
many] of the available baseline X-covariates to "adjust for" and (ii) which clustering
algorithm and dissimilarity metric to use. Unfortunately, changing these latter choices
requires the analyst to essentially "start over" ...i.e. invoking NUcluster() with changed
arguments, followed by an invocation of NUsetup() with a different 1st argument. To change
only one's choice of y-Outcome variable and/or the Treatment/Exposure variable, a new
NUsetup() invocation is all that is needed.
</p>


<h3>Value</h3>

<p> NULL </p>


<h3>Author(s)</h3>

<p>Bob Obenchain &lt;wizbob@att.net&gt;</p>


<h3>References</h3>

<p>Obenchain RL. (2010) Local Control Approach using JMP. Chapter 7 of
<b>Analysis of Observational Health Care Data using SAS</b>, <em>Cary, NC:SAS Press</em>,
pages 151-192.
</p>
<p>Obenchain RL. (2015) <b>NU_Confirm_Guidelines.pdf</b> http://localcontrolstatistics.org 
</p>
<p>Obenchain RL. (2023) <b>NU.Learning_in_R.pdf</b> http://localcontrolstatistics.org 
</p>
<p>Rubin DB. (1980) Bias reduction using Mahalanobis metric matching.
<em>Biometrics</em> <b>36</b>: 293-298.
</p>
<p>Tukey JW. (1977) <b>Exploratory Data Analysis</b>, <em>New York: Addison-Wesley</em>, Section 2C.
</p>


<h3>See Also</h3>

<p><code>ltdagg</code>, <code>ivadj</code> and <code>lrcagg</code>.</p>


<h3>Examples</h3>

<pre><code class="language-R">  
  # Running takes more than 7 seconds...
  data(pci15k)
  xvars   = c("stent", "height", "female", "diabetic", "acutemi", "ejfract", "ves1proc")
  hclobj  = NUcluster(pci15k, xvars)
  NU.env  = NUsetup(hclobj, pci15k, thin, surv6mo)
  surv050 = ltdagg( 50, NU.env)
  surv100 = ltdagg(100, NU.env)
  surv200 = ltdagg(200, NU.env)
  NUcompare(NU.env)
  
</code></pre>


</div>