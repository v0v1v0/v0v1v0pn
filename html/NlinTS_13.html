<div class="container">

<table style="width: 100%;"><tr>
<td>varmlp</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Artificial Neural Network VAR (Vector Auto-Regressive) model using a MultiLayer Perceptron, with the sigmoid activation function. The optimization algorithm is based on the stochastic gradient descent.</h2>

<h3>Description</h3>

<p>Artificial Neural Network VAR (Vector Auto-Regressive) model using a MultiLayer Perceptron, with the sigmoid activation function. The optimization algorithm is based on the stochastic gradient descent.
</p>


<h3>Usage</h3>

<pre><code class="language-R">varmlp(
  df,
  lag,
  sizeOfHLayers,
  iters = 50,
  learningRate = 0.01,
  algo = "sgd",
  batch_size = 10,
  bias = TRUE,
  seed = 5,
  activations = vector()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>df</code></td>
<td>
<p>A numerical dataframe</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lag</code></td>
<td>
<p>The lag parameter.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sizeOfHLayers</code></td>
<td>
<p>Integer vector that contains the size of hidden layers, where the length of this vector is the number of hidden layers, and the i-th element is the number of neurons in the i-th hidden layer.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iters</code></td>
<td>
<p>The number of iterations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>learningRate</code></td>
<td>
<p>The learning rate to use, O.1 by default, and if Adam algorithm is used, then it is the initial learning rate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>algo</code></td>
<td>
<p>String argument, for the optimisation algorithm to use, in choice ["sgd", "adam"]. By default "sgd" (stochastic gradient descent) is used. The algorithm 'adam' is to adapt the learning rate while using "sgd".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>batch_size</code></td>
<td>
<p>Integer argument for the batch size used in the back-propagation algorithm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bias</code></td>
<td>
<p>Logical, true if the bias have to be used in the network.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>Integer value for the seed used in the random generation of the weights of the network (a value = 0 will use the clock as random generator seed).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>activations</code></td>
<td>
<p>String vector for the activations functions to use (in choice ["sigmoid", "relu", "tanh"]). The length of this vector is the number of hidden layers plus one (the output layer). By default, the relu activation function is used in hidden layers, and the sigmoid in the last layer.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This function builds the model, and returns an object that can be used to make forecasts and can be updated from new data.
</p>


<h3>Value</h3>

<p>fit (df, iterations, batch_size):  fit/update the weights of the model from  the dataframe.
</p>
<p>forecast (df):   makes forecasts of an given dataframe. The forecasts include the forecasted row based on each previous "lag" rows, where the last one is the next forecasted row of  df.
</p>
<p>save (filename): save the model in a text file.
</p>
<p>load (filename): load the model from a text file.
</p>


<h3>Examples</h3>

<pre><code class="language-R">library (timeSeries) # to extract time series
library (NlinTS)
#load data
data = LPP2005REC
# Predict the last row of the data
train_data = data[1:(nrow (data) - 1), ]
model = varmlp (train_data, 1, c(10), 50, 0.01, "sgd", 30, TRUE, 0);
predictions = model$forecast (train_data)
print (predictions[nrow (predictions),])
</code></pre>


</div>