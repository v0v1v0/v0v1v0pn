<div class="container">

<table style="width: 100%;"><tr>
<td>entropy_cont</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Continuous  entropy</h2>

<h3>Description</h3>

<p>Continuous  entropy
</p>


<h3>Usage</h3>

<pre><code class="language-R">entropy_cont(V, k = 3, log = "loge")
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>V</code></td>
<td>
<p>Interger vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>Integer argument, the number of neighbors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>log</code></td>
<td>
<p>String argument in the set ("log2", "loge","log10"), which indicates the log function to use. The loge is used by default.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Computes the continuous entropy of a numerical vector using the Kozachenko approximation.
</p>


<h3>References</h3>


<p>Kraskov A, Stogbauer H, Grassberger P (2004).
“Estimating mutual information.”
<em>Phys. Rev. E</em>, <b>69</b>, 066138.
doi: <a href="https://doi.org/10.1103/PhysRevE.69.066138">10.1103/PhysRevE.69.066138</a>.

</p>


<h3>Examples</h3>

<pre><code class="language-R">library (timeSeries)
library (NlinTS)
#load data
data = LPP2005REC
print (entropy_cont (data[,1], 3))
</code></pre>


</div>