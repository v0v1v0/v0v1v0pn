<div class="container">

<table style="width: 100%;"><tr>
<td>mi_cont</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Continuous  Mutual Information</h2>

<h3>Description</h3>

<p>Continuous  Mutual Information
</p>


<h3>Usage</h3>

<pre><code class="language-R">mi_cont(X, Y, k = 3, algo = "ksg1", normalize = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>Integer vector, first time series.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>Integer vector, the second time series.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>Integer argument, the number of neighbors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>algo</code></td>
<td>
<p>String argument specifies the algorithm use ("ksg1", "ksg2"), as tow propositions of Kraskov estimation are provided. The first one ("ksg1") is used by default.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>normalize</code></td>
<td>
<p>Logical argument (FALSE by default)  for the option of normalizing the mutual information by dividing it by the joint entropy.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Computes the   Mutual Information between two vectors using the Kraskov estimator.
</p>


<h3>References</h3>


<p>Kraskov A, Stogbauer H, Grassberger P (2004).
“Estimating mutual information.”
<em>Phys. Rev. E</em>, <b>69</b>, 066138.
doi: <a href="https://doi.org/10.1103/PhysRevE.69.066138">10.1103/PhysRevE.69.066138</a>.

</p>


<h3>Examples</h3>

<pre><code class="language-R">library (timeSeries)
library (NlinTS)
#load data
data = LPP2005REC
print (mi_cont (data[,1], data[,2], 3, 'ksg1'))
print (mi_cont (data[,1], data[,2], 3, 'ksg2'))
</code></pre>


</div>