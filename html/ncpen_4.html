<div class="container">

<table style="width: 100%;"><tr>
<td>control.ncpen</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>control.ncpen: do preliminary works for <code>ncpen</code>.</h2>

<h3>Description</h3>

<p>The function returns controlled samples and tuning parameters for <code>ncpen</code> by eliminating unnecessary errors.
</p>


<h3>Usage</h3>

<pre><code class="language-R">control.ncpen(y.vec, x.mat, family = c("gaussian", "binomial", "poisson",
  "multinomial", "cox"), penalty = c("scad", "mcp", "tlp", "lasso",
  "classo", "ridge", "sridge", "mbridge", "mlog"), x.standardize = TRUE,
  intercept = TRUE, lambda = NULL, n.lambda = NULL,
  r.lambda = NULL, w.lambda = NULL, gamma = NULL, tau = NULL,
  alpha = NULL, aiter.max = 100, b.eps = 1e-07)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y.vec</code></td>
<td>
<p>(numeric vector) response vector.
Must be 0,1 for <code>binomial</code> and 1,2,..., for <code>multinomial</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x.mat</code></td>
<td>
<p>(numeric matrix) design matrix without intercept.
The censoring indicator must be included at the last column of the design matrix for <code>cox</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>family</code></td>
<td>
<p>(character) regression model. Supported models are
<code>gaussian</code>,
<code>binomial</code>,
<code>poisson</code>,
<code>multinomial</code>,
and <code>cox</code>.
Default is <code>gaussian</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>penalty</code></td>
<td>
<p>(character) penalty function.
Supported penalties are
<code>scad</code> (smoothly clipped absolute deviation),
<code>mcp</code> (minimax concave penalty),
<code>tlp</code> (truncated LASSO penalty),
<code>lasso</code> (least absolute shrinkage and selection operator),
<code>classo</code> (clipped lasso = mcp + lasso),
<code>ridge</code> (ridge),
<code>sridge</code> (sparse ridge = mcp + ridge),
<code>mbridge</code> (modified bridge) and
<code>mlog</code> (modified log).
Default is <code>scad</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x.standardize</code></td>
<td>
<p>(logical) whether to standardize <code>x.mat</code> prior to fitting the model (see details).
The estimated coefficients are always restored to the original scale.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intercept</code></td>
<td>
<p>(logical) whether to include an intercept in the model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>(numeric vector) user-specified sequence of <code>lambda</code> values.
Default is supplied automatically from samples.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.lambda</code></td>
<td>
<p>(numeric) the number of <code>lambda</code> values.
Default is 100.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>r.lambda</code></td>
<td>
<p>(numeric) ratio of the smallest <code>lambda</code> value to largest.
Default is 0.001 when n&gt;p, and 0.01 for other cases.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>w.lambda</code></td>
<td>
<p>(numeric vector) penalty weights for each coefficient (see references).
If a penalty weight is set to 0, the corresponding coefficient is always nonzero.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gamma</code></td>
<td>
<p>(numeric) additional tuning parameter for controlling shrinkage effect of <code>classo</code> and <code>sridge</code> (see references).
Default is half of the smallest <code>lambda</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tau</code></td>
<td>
<p>(numeric) concavity parameter of the penalties (see reference).
Default is 3.7 for <code>scad</code>, 2.1 for <code>mcp</code>, <code>classo</code> and <code>sridge</code>, 0.001 for <code>tlp</code>, <code>mbridge</code> and <code>mlog</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>(numeric) ridge effect (weight between the penalty and ridge penalty) (see details).
Default value is 1. If penalty is <code>ridge</code> and <code>sridge</code> then <code>alpha</code> is set to 0.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>aiter.max</code></td>
<td>
<p>(numeric) maximum number of iterations in CD algorithm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>b.eps</code></td>
<td>
<p>(numeric) convergence threshold for coefficients vector.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The function is used internal purpose but useful when users want to extract proper tuning parameters for <code>ncpen</code>.
Do not supply the samples from <code>control.ncpen</code> into <code>ncpen</code> or <code>cv.ncpen</code> directly to avoid unexpected errors.
</p>


<h3>Value</h3>

<p>An object with S3 class <code>ncpen</code>.
</p>
<table>
<tr style="vertical-align: top;">
<td><code>y.vec</code></td>
<td>
<p>response vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x.mat</code></td>
<td>
<p>design matrix adjusted to supplied options such as family and intercept.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>family</code></td>
<td>
<p>regression model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>penalty</code></td>
<td>
<p>penalty.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x.standardize</code></td>
<td>
<p>whether to standardize <code>x.mat</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intercept</code></td>
<td>
<p>whether to include the intercept.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>std</code></td>
<td>
<p>scale factor for <code>x.standardize</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>lambda values for the analysis.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.lambda</code></td>
<td>
<p>the number of <code>lambda</code> values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>r.lambda</code></td>
<td>
<p>ratio of the smallest <code>lambda</code> value to largest.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>w.lambda</code></td>
<td>
<p>penalty weights for each coefficient.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gamma</code></td>
<td>
<p>additional tuning parameter for controlling shrinkage effect of <code>classo</code> and <code>sridge</code> (see references).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tau</code></td>
<td>
<p>concavity parameter of the penalties (see references).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>ridge effect (amount of ridge penalty). see details.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Dongshin Kim, Sunghoon Kwon, Sangin Lee
</p>


<h3>References</h3>

<p>Fan, J. and Li, R. (2001). Variable selection via nonconcave penalized likelihood and its oracle properties.
<em>Journal of the American statistical Association</em>, 96, 1348-60.
Zhang, C.H. (2010). Nearly unbiased variable selection under minimax concave penalty.
<em>The Annals of statistics</em>, 38(2), 894-942.
Shen, X., Pan, W., Zhu, Y. and Zhou, H. (2013). On constrained and regularized high-dimensional regression.
<em>Annals of the Institute of Statistical Mathematics</em>, 65(5), 807-832.
Kwon, S., Lee, S. and Kim, Y. (2016). Moderately clipped LASSO.
<em>Computational Statistics and Data Analysis</em>, 92C, 53-67.
Kwon, S. Kim, Y. and Choi, H.(2013). Sparse bridge estimation with a diverging number of parameters.
<em>Statistics and Its Interface</em>, 6, 231-242.
Huang, J., Horowitz, J.L. and Ma, S. (2008). Asymptotic properties of bridge estimators in sparse high-dimensional regression models.
<em>The Annals of Statistics</em>, 36(2), 587-613.
Zou, H. and Li, R. (2008). One-step sparse estimates in nonconcave penalized likelihood models.
<em>Annals of statistics</em>, 36(4), 1509.
Lee, S., Kwon, S. and Kim, Y. (2016). A modified local quadratic approximation algorithm for penalized optimization problems.
<em>Computational Statistics and Data Analysis</em>, 94, 275-286.
</p>


<h3>See Also</h3>

<p><code>ncpen</code>, <code>cv.ncpen</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">### linear regression with scad penalty
sam =  sam.gen.ncpen(n=200,p=10,q=5,cf.min=0.5,cf.max=1,corr=0.5)
x.mat = sam$x.mat; y.vec = sam$y.vec
tun = control.ncpen(y.vec=y.vec,x.mat=x.mat,n.lambda=10,tau=1)
tun$tau
### multinomial regression with sridge penalty
sam =  sam.gen.ncpen(n=200,p=10,q=5,k=3,cf.min=0.5,cf.max=1,corr=0.5,family="multinomial")
x.mat = sam$x.mat; y.vec = sam$y.vec
tun = control.ncpen(y.vec=y.vec,x.mat=x.mat,n.lambda=10,
                    family="multinomial",penalty="sridge",gamma=10)
### cox regression with mcp penalty
sam =  sam.gen.ncpen(n=200,p=10,q=5,r=0.2,cf.min=0.5,cf.max=1,corr=0.5,family="cox")
x.mat = sam$x.mat; y.vec = sam$y.vec
tun = control.ncpen(y.vec=y.vec,x.mat=x.mat,n.lambda=10,family="cox",penalty="scad")
</code></pre>


</div>