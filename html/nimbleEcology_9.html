<div class="container">

<table style="width: 100%;"><tr>
<td>dDHMM</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Dynamic Hidden Markov Model distribution for use in <code>nimble</code> models</h2>

<h3>Description</h3>

<p><code>dDHMM</code> and <code>dDHMMo</code> provide Dynamic hidden Markov model
distributions for <code>nimble</code> models.
</p>


<h3>Usage</h3>

<pre><code class="language-R">dDHMM(x, init, probObs, probTrans, len, checkRowSums = 1, log = 0)

dDHMMo(x, init, probObs, probTrans, len, checkRowSums = 1, log = 0)

rDHMM(n, init, probObs, probTrans, len, checkRowSums = 1)

rDHMMo(n, init, probObs, probTrans, len, checkRowSums = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>vector of observations, each one a positive integer corresponding to
an observation state (one value of which could can correspond to "not
observed", and another value of which can correspond to "dead" or "removed
from system").</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>init</code></td>
<td>
<p>vector of initial state probabilities. Must sum to 1</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>probObs</code></td>
<td>
<p>time-independent matrix (<code>dDHMM</code> and <code>rDHMM</code>) or
time-dependent 3D array (<code>dDHMMo</code> and <code>rDHMMo</code>) of observation
probabilities.  First two dimensions of <code>probObs</code> are of size x
(number of possible system states) x (number of possible observation
classes). <code>dDHMMo</code> and <code>rDHMMo</code> expect an additional third
dimension of size (number of observation times). probObs[i, j (,t)] is the
probability that an individual in the ith latent state is recorded as being
in the jth detection state (at time t). See Details for more information.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>probTrans</code></td>
<td>
<p>time-dependent array of system state transition
probabilities. Dimension of <code>probTrans</code> is (number of possible system
states) x (number of possible system states) x (number of observation
times). probTrans[i,j,t] is the probability that an individual truly in
state i at time t will be in state j at time t+1.  See Details for more
information.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>len</code></td>
<td>
<p>length of observations (needed for rDHMM)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>checkRowSums</code></td>
<td>
<p>should validity of <code>probObs</code> and <code>probTrans</code> be
checked?  Both of these are required to have each set of probabilities sum
to 1 (over each row, or second dimension). If <code>checkRowSums</code> is
non-zero (or <code>TRUE</code>), these conditions will be checked within a
tolerance of 1e-6.  If it is 0 (or <code>FALSE</code>), they will not be checked.
Not checking should result in faster execution, but whether that is
appreciable will be case-specific.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>log</code></td>
<td>
<p><code>TRUE</code> or 1 to return log probability. <code>FALSE</code> or 0 to
return probability</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>number of random draws, each returning a vector of length
<code>len</code>. Currently only <code>n = 1</code> is supported, but the argument
exists for standardization of "<code>r</code>" functions</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>These nimbleFunctions provide distributions that can be used
directly in R or in <code>nimble</code> hierarchical models (via
<code>nimbleCode</code> and <code>nimbleModel</code>).
</p>
<p>The probability (or likelihood) of observation <code>x[t, o]</code> depends on the
previous true latent state, the time-dependent probability of transitioning
to a new state <code>probTrans</code>, and the probability of observation states
given the true latent state <code>probObs</code>.
</p>
<p>The distribution has two forms, <code>dDHMM</code> and <code>dDHMMo</code>. <code>dDHMM</code>
takes a time-independent observation probability matrix with dimension S x O,
while <code>dDHMMo</code> expects a three-dimensional array of time-dependent
observation probabilities with dimension S x O x T, where O is the number of
possible occupancy states, S is the number of true latent states, and T is
the number of time intervals.
</p>
<p><code>probTrans</code> has dimension S x S x (T - 1). <code>probTrans</code>[i, j, t] is
the probability that an individual in state <code>i</code> at time <code>t</code> takes
on state <code>j</code> at time <code>t+1</code>. The length of the third dimension may
be greater than (T - 1) but all values indexed greater than T - 1 will be
ignored.
</p>
<p><code>init</code> has length S. <code>init[i]</code> is the probability of being in state
<code>i</code> at the first observation time. That means that the first
observations arise from the initial state probabilities.
</p>
<p>For more explanation, see package vignette
(<code>vignette("Introduction_to_nimbleEcology")</code>).
</p>
<p>Compared to writing <code>nimble</code> models with a discrete true latent state
and a separate scalar datum for each observation, use of these distributions
allows one to directly sum (marginalize) over the discrete latent state and
calculate the probability of all observations from one site jointly.
</p>
<p>These are <code>nimbleFunction</code>s written in the format of user-defined
distributions for NIMBLE's extension of the BUGS model language. More
information can be found in the NIMBLE User Manual at
<a href="https://r-nimble.org">https://r-nimble.org</a>.
</p>
<p>When using these distributions in a <code>nimble</code> model, the left-hand side
will be used as <code>x</code>, and the user should not provide the <code>log</code>
argument.
</p>
<p>For example, in a NIMBLE model,
</p>
<p><code>observedStates[1:T] ~ dDHMM(initStates[1:S], observationProbs[1:S,
1:O], transitionProbs[1:S, 1:S, 1:(T-1)], 1, T)</code>
</p>
<p>declares that the <code>observedStates[1:T]</code> vector follows a dynamic hidden
Markov model distribution with parameters as indicated, assuming all the
parameters have been declared elsewhere in the model. In this case, <code>S</code>
is the number of system states, <code>O</code> is the number of observation
classes, and <code>T</code> is the number of observation occasions.This will invoke
(something like) the following call to <code>dDHMM</code> when <code>nimble</code> uses
the model such as for MCMC:
</p>
<p><code>rDHMM(observedStates[1:T], initStates[1:S], observationProbs[1:S, 1:O],
transitionProbs[1:S, 1:S, 1:(T-1)], 1, T, log = TRUE)</code>
</p>
<p>If an algorithm using a <code>nimble</code> model with this declaration needs to
generate a random draw for <code>observedStates[1:T]</code>, it will make a similar
invocation of <code>rDHMM</code>, with <code>n = 1</code>.
</p>
<p>If the observation probabilities are time-dependent, one would use:
</p>
<p><code>observedStates[1:T] ~ dDHMMo(initStates[1:S], observationProbs[1:S,
1:O, 1:T], transitionProbs[1:S, 1:S, 1:(T-1)], 1, T)</code>
</p>
<p>The <code>dDHMM[o]</code> distributions should work for models and algorithms that
use nimble's automatic differentiation (AD) system. In that system, some
kinds of values are "baked in" (cannot be changed) to the AD calculations
from the first call, unless and until the AD calculations are reset. For the
<code>dDHMM[o]</code> distributions, the sizes of the inputs and the data (<code>x</code>)
values themselves are baked in. These can be different for different
iterations through a for loop (or nimble model declarations with different
indices, for example), but the sizes and data values for each specific
iteration will be "baked in" after the first call. <b>In other words, it
is assumed that <code>x</code> are data and are not going to change.</b>
</p>


<h3>Value</h3>

<p>For <code>dDHMM</code> and <code>dDHMMo</code>: the probability (or likelihood)
or log probability of observation vector <code>x</code>. For <code>rDHMM</code> and
<code>rDHMMo</code>: a simulated detection history, <code>x</code>.
</p>


<h3>Author(s)</h3>

<p>Perry de Valpine, Daniel Turek, and Ben Goldstein
</p>


<h3>References</h3>

<p>D. Turek, P. de Valpine and C. J. Paciorek. 2016. Efficient Markov chain Monte
Carlo sampling for hierarchical hidden Markov models. Environmental and Ecological Statistics
23:549â€“564. DOI 10.1007/s10651-016-0353-z
</p>


<h3>See Also</h3>

<p>For hidden Markov models with time-independent transitions,
see dHMM and dHMMo.
For simple capture-recapture, see dCJS.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Set up constants and initial values for defining the model
dat &lt;- c(1,2,1,1) # A vector of observations
init &lt;- c(0.4, 0.2, 0.4) # A vector of initial state probabilities
probObs &lt;- t(array( # A matrix of observation probabilities
       c(1, 0,
         0, 1,
         0.8, 0.2), c(2, 3)))

probTrans &lt;- array(rep(1/3, 27), # A matrix of time-indexed transition probabilities
            c(3,3,3))

# Define code for a nimbleModel
 nc &lt;- nimbleCode({
   x[1:4] ~ dDHMM(init[1:3], probObs = probObs[1:3, 1:2],
                  probTrans = probTrans[1:3, 1:3, 1:3], len = 4, checkRowSums = 1)

   for (i in 1:3) {
     init[i] ~ dunif(0,1)

     for (j in 1:3) {
       for (t in 1:3) {
         probTrans[i,j,t] ~ dunif(0,1)
       }
     }

     probObs[i, 1] ~ dunif(0,1)
     probObs[i, 2] &lt;- 1 - probObs[i,1]
   }
 })

# Build the model, providing data and initial values
DHMM_model &lt;- nimbleModel(nc,
                          data = list(x = dat),
                          inits = list(init = init,
                                       probObs = probObs,
                                       probTrans = probTrans))
# Calculate log probability of x from the model
DHMM_model$calculate()
# Use the model for a variety of other purposes...
</code></pre>


</div>