<div class="container">

<table style="width: 100%;"><tr>
<td>nlmControl</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>nlmixr2 defaults controls for nlm</h2>

<h3>Description</h3>

<p>nlmixr2 defaults controls for nlm
</p>


<h3>Usage</h3>

<pre><code class="language-R">nlmControl(
  typsize = NULL,
  fscale = 1,
  print.level = 0,
  ndigit = NULL,
  gradtol = 1e-06,
  stepmax = NULL,
  steptol = 1e-06,
  iterlim = 10000,
  check.analyticals = FALSE,
  returnNlm = FALSE,
  solveType = c("hessian", "grad", "fun"),
  stickyRecalcN = 4,
  maxOdeRecalc = 5,
  odeRecalcFactor = 10^(0.5),
  eventType = c("central", "forward"),
  shiErr = (.Machine$double.eps)^(1/3),
  shi21maxFD = 20L,
  optimHessType = c("central", "forward"),
  hessErr = (.Machine$double.eps)^(1/3),
  shi21maxHess = 20L,
  useColor = crayon::has_color(),
  printNcol = floor((getOption("width") - 23)/12),
  print = 1L,
  normType = c("rescale2", "mean", "rescale", "std", "len", "constant"),
  scaleType = c("nlmixr2", "norm", "mult", "multAdd"),
  scaleCmax = 1e+05,
  scaleCmin = 1e-05,
  scaleC = NULL,
  scaleTo = 1,
  gradTo = 1,
  rxControl = NULL,
  optExpression = TRUE,
  sumProd = FALSE,
  literalFix = TRUE,
  addProp = c("combined2", "combined1"),
  calcTables = TRUE,
  compress = TRUE,
  covMethod = c("r", "nlm", ""),
  adjObf = TRUE,
  ci = 0.95,
  sigdig = 4,
  sigdigTable = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>typsize</code></td>
<td>
<p>an estimate of the size of each parameter
at the minimum.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fscale</code></td>
<td>
<p>an estimate of the size of <code>f</code> at the minimum.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>print.level</code></td>
<td>
<p>this argument determines the level of printing
which is done during the minimization process.  The default
value of <code>0</code> means that no printing occurs, a value of <code>1</code>
means that initial and final details are printed and a value
of 2 means that full tracing information is printed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ndigit</code></td>
<td>
<p>the number of significant digits in the function <code>f</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gradtol</code></td>
<td>
<p>a positive scalar giving the tolerance at which the
scaled gradient is considered close enough to zero to
terminate the algorithm.  The scaled gradient is a
measure of the relative change in <code>f</code> in each direction
<code>p[i]</code> divided by the relative change in <code>p[i]</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stepmax</code></td>
<td>
<p>a positive scalar which gives the maximum allowable
scaled step length.  <code>stepmax</code> is used to prevent steps which
would cause the optimization function to overflow, to prevent the
algorithm from leaving the area of interest in parameter space, or to
detect divergence in the algorithm. <code>stepmax</code> would be chosen
small enough to prevent the first two of these occurrences, but should
be larger than any anticipated reasonable step.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>steptol</code></td>
<td>
<p>A positive scalar providing the minimum allowable
relative step length.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iterlim</code></td>
<td>
<p>a positive integer specifying the maximum number of
iterations to be performed before the program is terminated.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>check.analyticals</code></td>
<td>
<p>a logical scalar specifying whether the
analytic gradients and Hessians, if they are supplied, should be
checked against numerical derivatives at the initial parameter
values. This can help detect incorrectly formulated gradients or
Hessians.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>returnNlm</code></td>
<td>
<p>is a logical that allows a return of the 'nlm'
object</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>solveType</code></td>
<td>
<p>tells if ‘nlm' will use nlmixr2’s analytical
gradients when available (finite differences will be used for
event-related parameters like parameters controlling lag time,
duration/rate of infusion, and modeled bioavailability). This can
be:
</p>
<p>- '"hessian"' which will use the analytical gradients to create a
Hessian with finite differences.
</p>
<p>- '"gradient"' which will use the gradient and let 'nlm' calculate
the finite difference hessian
</p>
<p>- '"fun"' where nlm will calculate both the finite difference
gradient and the finite difference Hessian
</p>
<p>When using nlmixr2's finite differences, the "ideal" step size for
either central or forward differences are optimized for with the
Shi2021 method which may give more accurate derivatives</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stickyRecalcN</code></td>
<td>
<p>The number of bad ODE solves before reducing
the atol/rtol for the rest of the problem.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxOdeRecalc</code></td>
<td>
<p>Maximum number of times to reduce the ODE
tolerances and try to resolve the system if there was a bad
ODE solve.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>odeRecalcFactor</code></td>
<td>
<p>The ODE recalculation factor when ODE
solving goes bad, this is the factor the rtol/atol is reduced</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eventType</code></td>
<td>
<p>Event gradient type for dosing events; Can be
"central" or "forward"</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>shiErr</code></td>
<td>
<p>This represents the epsilon when optimizing the ideal
step size for numeric differentiation using the Shi2021 method</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>shi21maxFD</code></td>
<td>
<p>The maximum number of steps for the optimization
of the forward difference step size when using dosing events (lag
time, modeled duration/rate and bioavailability)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>optimHessType</code></td>
<td>
<p>The hessian type for when calculating the
individual hessian by numeric differences (in generalized
log-likelihood estimation).  The options are "central", and
"forward".  The central differences is what R's 'optimHess()'
uses and is the default for this method. (Though the "forward" is
faster and still reasonable for most cases).  The Shi21 cannot be
changed for the Gill83 algorithm with the optimHess in a
generalized likelihood problem.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hessErr</code></td>
<td>
<p>This represents the epsilon when optimizing the
Hessian step size using the Shi2021 method.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>shi21maxHess</code></td>
<td>
<p>Maximum number of times to optimize the best
step size for the hessian calculation</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>useColor</code></td>
<td>
<p>Boolean indicating if focei can use ASCII color codes</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>printNcol</code></td>
<td>
<p>Number of columns to printout before wrapping
parameter estimates/gradient</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>print</code></td>
<td>
<p>Integer representing when the outer step is
printed. When this is 0 or do not print the iterations.  1 is
print every function evaluation (default), 5 is print every 5
evaluations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>normType</code></td>
<td>
<p>This is the type of parameter
normalization/scaling used to get the scaled initial values
for nlmixr2.  These are used with <code>scaleType</code> of.
</p>
<p>With the exception of <code>rescale2</code>, these come
from
<a href="https://en.wikipedia.org/wiki/Feature_scaling">Feature
Scaling</a>. The <code>rescale2</code> The rescaling is the same type
described in the
<a href="http://apmonitor.com/me575/uploads/Main/optimization_book.pdf">OptdesX</a>
software manual.
</p>
<p>In general, all all scaling formula can be described by:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{unscaled}-C_{1}</code>
</p>
<p>)/</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>

<p>Where
</p>
<p>The other data normalization approaches follow the following formula
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{unscaled}-C_{1}</code>
</p>
<p>)/</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>


<ul>
<li> <p><code>rescale2</code> This scales all parameters from (-1 to 1).
The relative differences between the parameters are preserved
with this approach and the constants are:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = (max(all unscaled values)+min(all unscaled values))/2
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = (max(all unscaled values) - min(all unscaled values))/2
</p>
</li>
<li> <p><code>rescale</code> or min-max normalization. This rescales all
parameters from (0 to 1).  As in the <code>rescale2</code> the
relative differences are preserved.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = min(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = max(all unscaled values) - min(all unscaled values)
</p>
</li>
<li> <p><code>mean</code> or mean normalization.  This rescales to center
the parameters around the mean but the parameters are from 0
to 1.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = mean(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = max(all unscaled values) - min(all unscaled values)
</p>
</li>
<li> <p><code>std</code> or standardization.  This standardizes by the mean
and standard deviation.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = mean(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = sd(all unscaled values)
</p>
</li>
<li> <p><code>len</code> or unit length scaling.  This scales the
parameters to the unit length.  For this approach we use the Euclidean length, that
is:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = 0
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">\sqrt(v_1^2 + v_2^2 + \cdots + v_n^2)</code>
</p>

</li>
<li> <p><code>constant</code> which does not perform data normalization. That is
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = 0
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = 1
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scaleType</code></td>
<td>
<p>The scaling scheme for nlmixr2.  The supported types are:
</p>

<ul>
<li> <p><code>nlmixr2</code>  In this approach the scaling is performed by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{current} - v_{init}</code>
</p>
<p>)*scaleC[i] + scaleTo
</p>
<p>The <code>scaleTo</code> parameter is specified by the <code>normType</code>,
and the scales are specified by <code>scaleC</code>.
</p>
</li>
<li> <p><code>norm</code> This approach uses the simple scaling provided
by the <code>normType</code> argument.
</p>
</li>
<li> <p><code>mult</code> This approach does not use the data
normalization provided by <code>normType</code>, but rather uses
multiplicative scaling to a constant provided by the <code>scaleTo</code>
argument.
</p>
<p>In this case:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">v_{current}</code>
</p>
<p>/</p>
<p style="text-align: center;"><code class="reqn">v_{init}</code>
</p>
<p>*scaleTo
</p>
</li>
<li> <p><code>multAdd</code> This approach changes the scaling based on
the parameter being specified.  If a parameter is defined in an
exponential block (ie exp(theta)), then it is scaled on a
linearly, that is:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{current}-v_{init}</code>
</p>
<p>) + scaleTo
</p>
<p>Otherwise the parameter is scaled multiplicatively.
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">v_{current}</code>
</p>
<p>/</p>
<p style="text-align: center;"><code class="reqn">v_{init}</code>
</p>
<p>*scaleTo
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scaleCmax</code></td>
<td>
<p>Maximum value of the scaleC to prevent overflow.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scaleCmin</code></td>
<td>
<p>Minimum value of the scaleC to prevent underflow.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scaleC</code></td>
<td>
<p>The scaling constant used with
<code>scaleType=nlmixr2</code>.  When not specified, it is based on
the type of parameter that is estimated.  The idea is to keep
the derivatives similar on a log scale to have similar
gradient sizes.  Hence parameters like log(exp(theta)) would
have a scaling factor of 1 and log(theta) would have a scaling
factor of ini_value (to scale by 1/value; ie
d/dt(log(ini_value)) = 1/ini_value or scaleC=ini_value)
</p>

<ul>
<li>
<p> For parameters in an exponential (ie exp(theta)) or
parameters specifying powers, boxCox or yeoJohnson
transformations , this is 1.
</p>
</li>
<li>
<p> For additive, proportional, lognormal error structures,
these are given by 0.5*abs(initial_estimate)
</p>
</li>
<li>
<p> Factorials are scaled by abs(1/digamma(initial_estimate+1))
</p>
</li>
<li>
<p> parameters in a log scale (ie log(theta)) are transformed
by log(abs(initial_estimate))*abs(initial_estimate)
</p>
</li>
</ul>
<p>These parameter scaling coefficients are chose to try to keep
similar slopes among parameters.  That is they all follow the
slopes approximately on a log-scale.
</p>
<p>While these are chosen in a logical manner, they may not always
apply.  You can specify each parameters scaling factor by this
parameter if you wish.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scaleTo</code></td>
<td>
<p>Scale the initial parameter estimate to this value.
By default this is 1.  When zero or below, no scaling is performed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gradTo</code></td>
<td>
<p>this is the factor that the gradient is scaled to
before optimizing.  This only works with
scaleType="nlmixr2".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rxControl</code></td>
<td>
<p>'rxode2' ODE solving options during fitting, created with 'rxControl()'</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>optExpression</code></td>
<td>
<p>Optimize the rxode2 expression to speed up
calculation. By default this is turned on.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sumProd</code></td>
<td>
<p>Is a boolean indicating if the model should change
multiplication to high precision multiplication and sums to
high precision sums using the PreciseSums package.  By default
this is <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>literalFix</code></td>
<td>
<p>boolean, substitute fixed population values as
literals and re-adjust ui and parameter estimates after
optimization; Default is 'TRUE'.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>addProp</code></td>
<td>
<p>specifies the type of additive plus proportional
errors, the one where standard deviations add (combined1) or the
type where the variances add (combined2).
</p>
<p>The combined1 error type can be described by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">y = f + (a + b\times f^c) \times \varepsilon</code>
</p>

<p>The combined2 error model can be described by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">y = f + \sqrt{a^2 + b^2\times f^{2\times c}} \times \varepsilon</code>
</p>

<p>Where:
</p>
<p>- y represents the observed value
</p>
<p>- f represents the predicted value
</p>
<p>- a  is the additive standard deviation
</p>
<p>- b is the proportional/power standard deviation
</p>
<p>- c is the power exponent (in the proportional case c=1)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>calcTables</code></td>
<td>
<p>This boolean is to determine if the foceiFit
will calculate tables. By default this is <code>TRUE</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>compress</code></td>
<td>
<p>Should the object have compressed items</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>covMethod</code></td>
<td>
<p>allows selection of "r", which uses nlmixr2's
'nlmixr2Hess()' for the hessian calculation or "nlm" which uses
the hessian from 'stats::nlm(.., hessian=TRUE)'. When using
‘nlmixr2’s‘ hessian for optimization or 'nlmixr2’s' gradient for
solving this defaults to "nlm" since 'stats::optimHess()' assumes
an accurate gradient and is faster than 'nlmixr2Hess'</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>adjObf</code></td>
<td>
<p>is a boolean to indicate if the objective function
should be adjusted to be closer to NONMEM's default objective
function.  By default this is <code>TRUE</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ci</code></td>
<td>
<p>Confidence level for some tables.  By default this is
0.95 or 95% confidence.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sigdig</code></td>
<td>
<p>Optimization significant digits. This controls:
</p>

<ul>
<li>
<p> The tolerance of the inner and outer optimization is <code>10^-sigdig</code>
</p>
</li>
<li>
<p> The tolerance of the ODE solvers is
<code>0.5*10^(-sigdig-2)</code>; For the sensitivity equations and
steady-state solutions the default is <code>0.5*10^(-sigdig-1.5)</code>
(sensitivity changes only applicable for liblsoda)
</p>
</li>
<li>
<p> The tolerance of the boundary check is <code>5 * 10 ^ (-sigdig + 1)</code>
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sigdigTable</code></td>
<td>
<p>Significant digits in the final output table.
If not specified, then it matches the significant digits in the
'sigdig' optimization algorithm.  If 'sigdig' is NULL, use 3.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Additional arguments passed to <code>nlmixr2est::nlmControl()</code>.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>nlm control object
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>


<h3>Examples</h3>

<pre><code class="language-R">
# A logit regression example with emax model

dsn &lt;- data.frame(i=1:1000)
dsn$time &lt;- exp(rnorm(1000))
dsn$DV=rbinom(1000,1,exp(-1+dsn$time)/(1+exp(-1+dsn$time)))

mod &lt;- function() {
 ini({
   E0 &lt;- 0.5
   Em &lt;- 0.5
   E50 &lt;- 2
   g &lt;- fix(2)
 })
 model({
   v &lt;- E0+Em*time^g/(E50^g+time^g)
   ll(bin) ~ DV * v - log(1 + exp(v))
 })
}

fit2 &lt;- nlmixr(mod, dsn, est="nlm")

print(fit2)

# you can also get the nlm output with fit2$nlm

fit2$nlm

# The nlm control has been modified slightly to include
# extra components and name the parameters

</code></pre>


</div>