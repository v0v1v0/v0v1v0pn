<div class="container">

<table style="width: 100%;"><tr>
<td>nlsControl</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>nlmixr2 defaults controls for nls</h2>

<h3>Description</h3>

<p>nlmixr2 defaults controls for nls
</p>


<h3>Usage</h3>

<pre><code class="language-R">nlsControl(
  maxiter = 10000,
  tol = 1e-05,
  minFactor = 1/1024,
  printEval = FALSE,
  warnOnly = FALSE,
  scaleOffset = 0,
  nDcentral = FALSE,
  algorithm = c("LM", "default", "plinear", "port"),
  ftol = sqrt(.Machine$double.eps),
  ptol = sqrt(.Machine$double.eps),
  gtol = 0,
  diag = list(),
  epsfcn = 0,
  factor = 100,
  maxfev = integer(),
  nprint = 0,
  solveType = c("grad", "fun"),
  stickyRecalcN = 4,
  maxOdeRecalc = 5,
  odeRecalcFactor = 10^(0.5),
  eventType = c("central", "forward"),
  shiErr = (.Machine$double.eps)^(1/3),
  shi21maxFD = 20L,
  useColor = crayon::has_color(),
  printNcol = floor((getOption("width") - 23)/12),
  print = 1L,
  normType = c("rescale2", "mean", "rescale", "std", "len", "constant"),
  scaleType = c("nlmixr2", "norm", "mult", "multAdd"),
  scaleCmax = 1e+05,
  scaleCmin = 1e-05,
  scaleC = NULL,
  scaleTo = 1,
  gradTo = 1,
  trace = FALSE,
  rxControl = NULL,
  optExpression = TRUE,
  sumProd = FALSE,
  literalFix = TRUE,
  returnNls = FALSE,
  addProp = c("combined2", "combined1"),
  calcTables = TRUE,
  compress = TRUE,
  adjObf = TRUE,
  ci = 0.95,
  sigdig = 4,
  sigdigTable = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>maxiter</code></td>
<td>
<p>A positive integer specifying the maximum number of
iterations allowed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>A positive numeric value specifying the tolerance level for
the relative offset convergence criterion.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>minFactor</code></td>
<td>
<p>A positive numeric value specifying the minimum
step-size factor allowed on any step in the iteration.  The
increment is calculated with a Gauss-Newton algorithm and
successively halved until the residual sum of squares has been
decreased or until the step-size factor has been reduced below this
limit.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>printEval</code></td>
<td>
<p>a logical specifying whether the number of evaluations
(steps in the gradient direction taken each iteration) is printed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>warnOnly</code></td>
<td>
<p>a logical specifying whether <code>nls()</code> should
return instead of signalling an error in the case of termination
before convergence.
Termination before convergence happens upon completion of <code>maxiter</code>
iterations, in the case of a singular gradient, and in the case that the
step-size factor is reduced below <code>minFactor</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scaleOffset</code></td>
<td>
<p>a constant to be added to the denominator of the relative
offset convergence criterion calculation to avoid a zero divide in the case
where the fit of a model to data is very close.  The default value of
<code>0</code> keeps the legacy behaviour of <code>nls()</code>.  A value such as
<code>1</code> seems to work for problems of reasonable scale with very small
residuals.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nDcentral</code></td>
<td>
<p>only when <em>numerical</em> derivatives are used:
<code>logical</code> indicating if <em>central</em> differences
should be employed, i.e., <code>numericDeriv(*, central=TRUE)</code>
be used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>algorithm</code></td>
<td>
<p>character string specifying the algorithm to use.
The default algorithm is a Gauss-Newton algorithm.  Other possible
values are <code>"plinear"</code> for the Golub-Pereyra algorithm for
partially linear least-squares models and <code>"port"</code> for the
‘nl2sol’ algorithm from the Port library – see the
references.  Can be abbreviated.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ftol</code></td>
<td>
<p>non-negative numeric. Termination occurs when
both the actual and predicted relative reductions in the sum of
squares are at most <code>ftol</code>. Therefore, <code>ftol</code> measures
the relative error desired in the sum of squares.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ptol</code></td>
<td>
<p>non-negative numeric. Termination occurs when
the relative error between two consecutive iterates is at most
<code>ptol</code>. Therefore, <code>ptol</code> measures the relative error
desired in the approximate solution.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gtol</code></td>
<td>
<p>non-negative numeric. Termination occurs when
the cosine of the angle between result of <code>fn</code> evaluation
<code class="reqn">fvec</code> and any column of the Jacobian is at most <code>gtol</code>
in absolute value. Therefore, <code>gtol</code> measures the
orthogonality desired between the function vector and the
columns of the Jacobian.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>diag</code></td>
<td>
<p>a list or numeric vector containing positive
entries that serve as multiplicative scale factors for the
parameters. Length of <code>diag</code> should be equal to that of
<code>par</code>. If not, user-provided <code>diag</code> is ignored and
<code>diag</code> is internally set.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>epsfcn</code></td>
<td>
<p>(used if <code>jac</code> is not provided) is a
numeric used in determining a suitable step for the
forward-difference approximation. This approximation assumes
that the relative errors in the functions are of the order of
<code>epsfcn</code>. If <code>epsfcn</code> is less than the machine
precision, it is assumed that the relative errors in the
functions are of the order of the machine precision.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>factor</code></td>
<td>
<p>positive numeric, used in determining the
initial step bound.  This bound is set to the product of
<code>factor</code> and the <code class="reqn">|\code{diag}*\code{par}|</code> if nonzero,
or else to <code>factor</code> itself. In most cases <code>factor</code>
should lie in the interval (0.1,100). 100 is a generally
recommended value.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxfev</code></td>
<td>
<p>integer; termination occurs
when the number of calls to <code>fn</code> has reached <code>maxfev</code>.
Note that <code>nls.lm</code> sets the value of <code>maxfev</code> to 
<code>100*(length(par) + 1)</code> if 
<code>maxfev = integer()</code>, where <code>par</code> is the list or
vector of parameters to be optimized.  </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nprint</code></td>
<td>
<p>is an integer; set <code>nprint</code> to be positive
to enable printing of iterates</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>solveType</code></td>
<td>
<p>tells if ‘nlm' will use nlmixr2’s analytical
gradients when available (finite differences will be used for
event-related parameters like parameters controlling lag time,
duration/rate of infusion, and modeled bioavailability). This can
be:
</p>
<p>- '"hessian"' which will use the analytical gradients to create a
Hessian with finite differences.
</p>
<p>- '"gradient"' which will use the gradient and let 'nlm' calculate
the finite difference hessian
</p>
<p>- '"fun"' where nlm will calculate both the finite difference
gradient and the finite difference Hessian
</p>
<p>When using nlmixr2's finite differences, the "ideal" step size for
either central or forward differences are optimized for with the
Shi2021 method which may give more accurate derivatives</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stickyRecalcN</code></td>
<td>
<p>The number of bad ODE solves before reducing
the atol/rtol for the rest of the problem.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxOdeRecalc</code></td>
<td>
<p>Maximum number of times to reduce the ODE
tolerances and try to resolve the system if there was a bad
ODE solve.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>odeRecalcFactor</code></td>
<td>
<p>The ODE recalculation factor when ODE
solving goes bad, this is the factor the rtol/atol is reduced</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eventType</code></td>
<td>
<p>Event gradient type for dosing events; Can be
"central" or "forward"</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>shiErr</code></td>
<td>
<p>This represents the epsilon when optimizing the ideal
step size for numeric differentiation using the Shi2021 method</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>shi21maxFD</code></td>
<td>
<p>The maximum number of steps for the optimization
of the forward difference step size when using dosing events (lag
time, modeled duration/rate and bioavailability)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>useColor</code></td>
<td>
<p>Boolean indicating if focei can use ASCII color codes</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>printNcol</code></td>
<td>
<p>Number of columns to printout before wrapping
parameter estimates/gradient</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>print</code></td>
<td>
<p>Integer representing when the outer step is
printed. When this is 0 or do not print the iterations.  1 is
print every function evaluation (default), 5 is print every 5
evaluations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>normType</code></td>
<td>
<p>This is the type of parameter
normalization/scaling used to get the scaled initial values
for nlmixr2.  These are used with <code>scaleType</code> of.
</p>
<p>With the exception of <code>rescale2</code>, these come
from
<a href="https://en.wikipedia.org/wiki/Feature_scaling">Feature
Scaling</a>. The <code>rescale2</code> The rescaling is the same type
described in the
<a href="http://apmonitor.com/me575/uploads/Main/optimization_book.pdf">OptdesX</a>
software manual.
</p>
<p>In general, all all scaling formula can be described by:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{unscaled}-C_{1}</code>
</p>
<p>)/</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>

<p>Where
</p>
<p>The other data normalization approaches follow the following formula
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{unscaled}-C_{1}</code>
</p>
<p>)/</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>


<ul>
<li> <p><code>rescale2</code> This scales all parameters from (-1 to 1).
The relative differences between the parameters are preserved
with this approach and the constants are:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = (max(all unscaled values)+min(all unscaled values))/2
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = (max(all unscaled values) - min(all unscaled values))/2
</p>
</li>
<li> <p><code>rescale</code> or min-max normalization. This rescales all
parameters from (0 to 1).  As in the <code>rescale2</code> the
relative differences are preserved.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = min(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = max(all unscaled values) - min(all unscaled values)
</p>
</li>
<li> <p><code>mean</code> or mean normalization.  This rescales to center
the parameters around the mean but the parameters are from 0
to 1.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = mean(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = max(all unscaled values) - min(all unscaled values)
</p>
</li>
<li> <p><code>std</code> or standardization.  This standardizes by the mean
and standard deviation.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = mean(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = sd(all unscaled values)
</p>
</li>
<li> <p><code>len</code> or unit length scaling.  This scales the
parameters to the unit length.  For this approach we use the Euclidean length, that
is:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = 0
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">\sqrt(v_1^2 + v_2^2 + \cdots + v_n^2)</code>
</p>

</li>
<li> <p><code>constant</code> which does not perform data normalization. That is
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = 0
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = 1
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scaleType</code></td>
<td>
<p>The scaling scheme for nlmixr2.  The supported types are:
</p>

<ul>
<li> <p><code>nlmixr2</code>  In this approach the scaling is performed by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{current} - v_{init}</code>
</p>
<p>)*scaleC[i] + scaleTo
</p>
<p>The <code>scaleTo</code> parameter is specified by the <code>normType</code>,
and the scales are specified by <code>scaleC</code>.
</p>
</li>
<li> <p><code>norm</code> This approach uses the simple scaling provided
by the <code>normType</code> argument.
</p>
</li>
<li> <p><code>mult</code> This approach does not use the data
normalization provided by <code>normType</code>, but rather uses
multiplicative scaling to a constant provided by the <code>scaleTo</code>
argument.
</p>
<p>In this case:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">v_{current}</code>
</p>
<p>/</p>
<p style="text-align: center;"><code class="reqn">v_{init}</code>
</p>
<p>*scaleTo
</p>
</li>
<li> <p><code>multAdd</code> This approach changes the scaling based on
the parameter being specified.  If a parameter is defined in an
exponential block (ie exp(theta)), then it is scaled on a
linearly, that is:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{current}-v_{init}</code>
</p>
<p>) + scaleTo
</p>
<p>Otherwise the parameter is scaled multiplicatively.
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">v_{current}</code>
</p>
<p>/</p>
<p style="text-align: center;"><code class="reqn">v_{init}</code>
</p>
<p>*scaleTo
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scaleCmax</code></td>
<td>
<p>Maximum value of the scaleC to prevent overflow.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scaleCmin</code></td>
<td>
<p>Minimum value of the scaleC to prevent underflow.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scaleC</code></td>
<td>
<p>The scaling constant used with
<code>scaleType=nlmixr2</code>.  When not specified, it is based on
the type of parameter that is estimated.  The idea is to keep
the derivatives similar on a log scale to have similar
gradient sizes.  Hence parameters like log(exp(theta)) would
have a scaling factor of 1 and log(theta) would have a scaling
factor of ini_value (to scale by 1/value; ie
d/dt(log(ini_value)) = 1/ini_value or scaleC=ini_value)
</p>

<ul>
<li>
<p> For parameters in an exponential (ie exp(theta)) or
parameters specifying powers, boxCox or yeoJohnson
transformations , this is 1.
</p>
</li>
<li>
<p> For additive, proportional, lognormal error structures,
these are given by 0.5*abs(initial_estimate)
</p>
</li>
<li>
<p> Factorials are scaled by abs(1/digamma(initial_estimate+1))
</p>
</li>
<li>
<p> parameters in a log scale (ie log(theta)) are transformed
by log(abs(initial_estimate))*abs(initial_estimate)
</p>
</li>
</ul>
<p>These parameter scaling coefficients are chose to try to keep
similar slopes among parameters.  That is they all follow the
slopes approximately on a log-scale.
</p>
<p>While these are chosen in a logical manner, they may not always
apply.  You can specify each parameters scaling factor by this
parameter if you wish.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scaleTo</code></td>
<td>
<p>Scale the initial parameter estimate to this value.
By default this is 1.  When zero or below, no scaling is performed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gradTo</code></td>
<td>
<p>this is the factor that the gradient is scaled to
before optimizing.  This only works with
scaleType="nlmixr2".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>trace</code></td>
<td>
<p>logical value indicating if a trace of the iteration
progress should be printed.  Default is <code>FALSE</code>.  If
<code>TRUE</code> the residual (weighted) sum-of-squares, the convergence
criterion and the parameter values are printed at the conclusion of
each iteration.  Note that <code>format()</code> is used, so these
mostly depend on <code>getOption("digits")</code>.
When the <code>"plinear"</code> algorithm is used, the conditional
estimates of the linear parameters are printed after the nonlinear
parameters.  When the <code>"port"</code> algorithm is used the
objective function value printed is half the residual (weighted)
sum-of-squares.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rxControl</code></td>
<td>
<p>'rxode2' ODE solving options during fitting, created with 'rxControl()'</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>optExpression</code></td>
<td>
<p>Optimize the rxode2 expression to speed up
calculation. By default this is turned on.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sumProd</code></td>
<td>
<p>Is a boolean indicating if the model should change
multiplication to high precision multiplication and sums to
high precision sums using the PreciseSums package.  By default
this is <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>literalFix</code></td>
<td>
<p>boolean, substitute fixed population values as
literals and re-adjust ui and parameter estimates after
optimization; Default is 'TRUE'.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>returnNls</code></td>
<td>
<p>logical; when TRUE, will return the nls object
instead of the nlmixr object</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>addProp</code></td>
<td>
<p>specifies the type of additive plus proportional
errors, the one where standard deviations add (combined1) or the
type where the variances add (combined2).
</p>
<p>The combined1 error type can be described by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">y = f + (a + b\times f^c) \times \varepsilon</code>
</p>

<p>The combined2 error model can be described by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">y = f + \sqrt{a^2 + b^2\times f^{2\times c}} \times \varepsilon</code>
</p>

<p>Where:
</p>
<p>- y represents the observed value
</p>
<p>- f represents the predicted value
</p>
<p>- a  is the additive standard deviation
</p>
<p>- b is the proportional/power standard deviation
</p>
<p>- c is the power exponent (in the proportional case c=1)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>calcTables</code></td>
<td>
<p>This boolean is to determine if the foceiFit
will calculate tables. By default this is <code>TRUE</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>compress</code></td>
<td>
<p>Should the object have compressed items</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>adjObf</code></td>
<td>
<p>is a boolean to indicate if the objective function
should be adjusted to be closer to NONMEM's default objective
function.  By default this is <code>TRUE</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ci</code></td>
<td>
<p>Confidence level for some tables.  By default this is
0.95 or 95% confidence.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sigdig</code></td>
<td>
<p>Optimization significant digits. This controls:
</p>

<ul>
<li>
<p> The tolerance of the inner and outer optimization is <code>10^-sigdig</code>
</p>
</li>
<li>
<p> The tolerance of the ODE solvers is
<code>0.5*10^(-sigdig-2)</code>; For the sensitivity equations and
steady-state solutions the default is <code>0.5*10^(-sigdig-1.5)</code>
(sensitivity changes only applicable for liblsoda)
</p>
</li>
<li>
<p> The tolerance of the boundary check is <code>5 * 10 ^ (-sigdig + 1)</code>
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sigdigTable</code></td>
<td>
<p>Significant digits in the final output table.
If not specified, then it matches the significant digits in the
'sigdig' optimization algorithm.  If 'sigdig' is NULL, use 3.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Additional optional arguments.  None are used at present.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>nls control object
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>


<h3>Examples</h3>

<pre><code class="language-R">

if (rxode2::.linCmtSensB()) {

one.cmt &lt;- function() {
  ini({
   tka &lt;- 0.45
   tcl &lt;- log(c(0, 2.7, 100))
   tv &lt;- 3.45
   add.sd &lt;- 0.7
 })
 model({
   ka &lt;- exp(tka)
   cl &lt;- exp(tcl)
   v &lt;- exp(tv)
   linCmt() ~ add(add.sd)
 })
}

# Uses nlsLM from minpack.lm if available

fit1 &lt;- nlmixr(one.cmt, nlmixr2data::theo_sd, est="nls", nlsControl(algorithm="LM"))

# Uses port and respect parameter boundaries
fit2 &lt;- nlmixr(one.cmt, nlmixr2data::theo_sd, est="nls", nlsControl(algorithm="port"))

# You can access the underlying nls object with `$nls`
fit2$nls
}

</code></pre>


</div>