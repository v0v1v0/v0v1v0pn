<div class="container">

<table style="width: 100%;"><tr>
<td>crs2lm</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Controlled Random Search</h2>

<h3>Description</h3>

<p>The Controlled Random Search (CRS) algorithm (and in particular, the CRS2
variant) with the ‘local mutation’ modification.
</p>


<h3>Usage</h3>

<pre><code class="language-R">crs2lm(
  x0,
  fn,
  lower,
  upper,
  maxeval = 10000,
  pop.size = 10 * (length(x0) + 1),
  ranseed = NULL,
  xtol_rel = 1e-06,
  nl.info = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x0</code></td>
<td>
<p>initial point for searching the optimum.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fn</code></td>
<td>
<p>objective function that is to be minimized.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lower, upper</code></td>
<td>
<p>lower and upper bound constraints.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxeval</code></td>
<td>
<p>maximum number of function evaluations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pop.size</code></td>
<td>
<p>population size.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ranseed</code></td>
<td>
<p>prescribe seed for random number generator.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xtol_rel</code></td>
<td>
<p>stopping criterion for relative change reached.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nl.info</code></td>
<td>
<p>logical; shall the original NLopt info been shown.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>additional arguments passed to the function.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The CRS algorithms are sometimes compared to genetic algorithms, in that
they start with a random population of points, and randomly evolve these
points by heuristic rules. In this case, the evolution somewhat resembles a
randomized Nelder-Mead algorithm.
</p>
<p>The published results for CRS seem to be largely empirical.
</p>


<h3>Value</h3>

<p>List with components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>par</code></td>
<td>
<p>the optimal solution found so far.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>value</code></td>
<td>
<p>the function value corresponding to <code>par</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iter</code></td>
<td>
<p>number of (outer) iterations, see <code>maxeval</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>convergence</code></td>
<td>
<p>integer code indicating successful completion (&gt; 0)
or a possible error number (&lt; 0).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>message</code></td>
<td>
<p>character string produced by NLopt and giving additional
information.</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>The initial population size for CRS defaults to <code>10x(n+1)</code> in
<code>n</code> dimensions, but this can be changed; the initial population must be
at least <code>n+1</code>.
</p>


<h3>References</h3>

<p>W. L. Price, “Global optimization by controlled random
search,” J. Optim. Theory Appl. 40 (3), p. 333-348 (1983).
</p>
<p>P. Kaelo and M. M. Ali, “Some variants of the controlled random search
algorithm for global optimization,” J. Optim. Theory Appl. 130 (2), 253-264
(2006).
</p>


<h3>Examples</h3>

<pre><code class="language-R">
### Minimize the Hartmann6 function
hartmann6 &lt;- function(x) {
    n &lt;- length(x)
    a &lt;- c(1.0, 1.2, 3.0, 3.2)
    A &lt;- matrix(c(10.0,  0.05, 3.0, 17.0,
                   3.0, 10.0,  3.5,  8.0,
                  17.0, 17.0,  1.7,  0.05,
                   3.5,  0.1, 10.0, 10.0,
                   1.7,  8.0, 17.0,  0.1,
                   8.0, 14.0,  8.0, 14.0), nrow=4, ncol=6)
    B  &lt;- matrix(c(.1312,.2329,.2348,.4047,
                   .1696,.4135,.1451,.8828,
                   .5569,.8307,.3522,.8732,
                   .0124,.3736,.2883,.5743,
                   .8283,.1004,.3047,.1091,
                   .5886,.9991,.6650,.0381), nrow=4, ncol=6)
    fun &lt;- 0.0
    for (i in 1:4) {
        fun &lt;- fun - a[i] * exp(-sum(A[i,]*(x-B[i,])^2))
    }
    return(fun)
}

S &lt;- mlsl(x0 = rep(0, 6), hartmann6, lower = rep(0,6), upper = rep(1,6),
            nl.info = TRUE, control=list(xtol_rel=1e-8, maxeval=1000))
## Number of Iterations....: 4050
## Termination conditions:  maxeval: 10000	xtol_rel: 1e-06
## Number of inequality constraints:  0
## Number of equality constraints:    0
## Optimal value of objective function:  -3.32236801141328
## Optimal value of controls:
##     0.2016893 0.1500105 0.4768738 0.2753326 0.3116516 0.6573004

</code></pre>


</div>