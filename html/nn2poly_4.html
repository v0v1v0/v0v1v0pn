<div class="container">

<table style="width: 100%;"><tr>
<td>luz_model_sequential</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Build a <code>luz</code> model composed of a linear stack of layers</h2>

<h3>Description</h3>

<p>Helper function to build <code>luz</code> models as a sequential model, by feeding
it a stack of <code>luz</code> layers.
</p>


<h3>Usage</h3>

<pre><code class="language-R">luz_model_sequential(...)
</code></pre>


<h3>Arguments</h3>

<table><tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Sequence of modules to be added.</p>
</td>
</tr></table>
<h3>Details</h3>

<p>This step is needed so we can get the activation functions and
layers and neurons architecture easily with <code>nn2poly:::get_parameters()</code>.
Furthermore, this step is also needed to be able to impose the needed
constraints when using the <code>luz/torch</code> framework.
</p>


<h3>Value</h3>

<p>A <code>nn_sequential</code> module.
</p>


<h3>See Also</h3>

<p><code>add_constraints()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
if (requireNamespace("luz", quietly=TRUE)) {
# Create a NN using luz/torch as a sequential model
# with 3 fully connected linear layers,
# the first one with input = 5 variables,
# 100 neurons and tanh activation function, the second
# one with 50 neurons and softplus activation function
# and the last one with 1 linear output.
nn &lt;- luz_model_sequential(
  torch::nn_linear(5,100),
  torch::nn_tanh(),
  torch::nn_linear(100,50),
  torch::nn_softplus(),
  torch::nn_linear(50,1)
)

nn

# Check that the nn is of class nn_squential
class(nn)
}

## End(Not run)

</code></pre>


</div>