<div class="container">

<table style="width: 100%;"><tr>
<td>plot.nn2poly</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Plot method for <code>nn2poly</code> objects.</h2>

<h3>Description</h3>

<p>A function that takes a polynomial (or several ones) as given by the
<span class="pkg">nn2poly</span> algorithm, and then plots their absolute magnitude as barplots
to be able to compare the most important coefficients.
</p>


<h3>Usage</h3>

<pre><code class="language-R">## S3 method for class 'nn2poly'
plot(x, ..., n = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A <code>nn2poly</code> object, as returned by the <span class="pkg">nn2poly</span> algorithm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Ignored.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>An integer denoting the number of coefficients to be plotted,
after ordering them by absolute magnitude.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The plot method represents only the polynomials at the final layer, even if
<code>x</code> is generated using <code>nn2poly()</code> with <code>keep_layers=TRUE</code>.
</p>


<h3>Value</h3>

<p>A plot showing the <code>n</code> most important coefficients.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># --- Single polynomial output ---
# Build a NN structure with random weights, with 2 (+ bias) inputs,
# 4 (+bias) neurons in the first hidden layer with "tanh" activation
# function, 4 (+bias) neurons in the second hidden layer with "softplus",
# and 2 "linear" output units

weights_layer_1 &lt;- matrix(rnorm(12), nrow = 3, ncol = 4)
weights_layer_2 &lt;- matrix(rnorm(20), nrow = 5, ncol = 4)
weights_layer_3 &lt;- matrix(rnorm(5), nrow = 5, ncol = 1)

# Set it as a list with activation functions as names
nn_object = list("tanh" = weights_layer_1,
                 "softplus" = weights_layer_2,
                 "linear" = weights_layer_3)

# Obtain the polynomial representation (order = 3) of that neural network
final_poly &lt;- nn2poly(nn_object, max_order = 3)

# Plot all the coefficients, one plot per output unit
plot(final_poly)

# Plot only the 5 most important coeffcients (by absolute magnitude)
# one plot per output unit
plot(final_poly, n = 5)

# --- Multiple output polynomials ---
# Build a NN structure with random weights, with 2 (+ bias) inputs,
# 4 (+bias) neurons in the first hidden layer with "tanh" activation
# function, 4 (+bias) neurons in the second hidden layer with "softplus",
# and 2 "linear" output units

weights_layer_1 &lt;- matrix(rnorm(12), nrow = 3, ncol = 4)
weights_layer_2 &lt;- matrix(rnorm(20), nrow = 5, ncol = 4)
weights_layer_3 &lt;- matrix(rnorm(10), nrow = 5, ncol = 2)

# Set it as a list with activation functions as names
nn_object = list("tanh" = weights_layer_1,
                 "softplus" = weights_layer_2,
                 "linear" = weights_layer_3)

# Obtain the polynomial representation (order = 3) of that neural network
final_poly &lt;- nn2poly(nn_object, max_order = 3)

# Plot all the coefficients, one plot per output unit
plot(final_poly)

# Plot only the 5 most important coeffcients (by absolute magnitude)
# one plot per output unit
plot(final_poly, n = 5)

</code></pre>


</div>