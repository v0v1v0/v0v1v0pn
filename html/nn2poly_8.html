<div class="container">

<table style="width: 100%;"><tr>
<td>plot_taylor_and_activation_potentials</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Plots activation potentials and Taylor expansion.</h2>

<h3>Description</h3>

<p>Function that allows to take a NN and the data input values
and plot the distribution of data activation potentials
(sum of input values * weights) at all neurons together at each layer
with the Taylor expansion used in the activation functions. If any layer
is <code>'linear'</code> (usually will be the output), then that layer will not
be an approximation as Taylor expansion is not needed.
</p>


<h3>Usage</h3>

<pre><code class="language-R">plot_taylor_and_activation_potentials(
  object,
  data,
  max_order,
  taylor_orders = 8,
  constraints,
  taylor_interval = 1.5,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>An object for which the computation of the NN2Poly algorithm is
desired. Currently supports models from the following deep learning frameworks:
</p>

<ul>
<li> <p><code>tensorflow</code>/<code>keras</code> models built as a sequential model.
</p>
</li>
<li> <p><code>torch</code>/<code>luz</code> models built as a sequential model.
</p>
</li>
</ul>
<p>It also supports a named <code>list</code> as input which allows to introduce by
hand a model from any other source. This <code>list</code> should be of length L
(number of hidden layers + 1) containing the weights matrix for each layer.
Each element of the list should be named as the activation function used at
each layer. Currently supported activation functions are <code>"tanh"</code>,
<code>"softplus"</code>, <code>"sigmoid"</code> and <code>"linear"</code>.
</p>
<p>At any layer <code class="reqn">l</code>, the expected shape of such matrices is of the form
<code class="reqn">(h_{(l-1)} + 1)*(h_l)</code>, that is, the number of rows is the number of
neurons in the previous layer plus the bias vector, and the number of columns
is the number of neurons in the current layer L. Therefore, each column
corresponds to the weight vector affecting each neuron in that layer.
The bias vector should be in the first row.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>Matrix or data frame containing the predictor variables (X)
to be used as input to compute their activation potentials. The response
variable column should not be included.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_order</code></td>
<td>
<p><code>integer</code> that determines the maximum order
that will be forced in the final polynomial, discarding terms of higher order
that would naturally arise when considering all Taylor expansions allowed by
<code>taylor_orders</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>taylor_orders</code></td>
<td>
<p><code>integer</code> or <code>vector</code> of length L that sets the
degree at which Taylor expansion is truncated at each layer. If a single
value is used, that value is set for each non linear layer and 1 for linear
at each layer activation function. Default set to <code>8</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>constraints</code></td>
<td>
<p>Boolean parameter determining if the NN is constrained
(TRUE) or not (FALSE). This only modifies the plots title to show
"constrained" or "unconstrained" respectively.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>taylor_interval</code></td>
<td>
<p>optional parameter determining the interval in which
the Taylor expansion is represented. Default is 1.5.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Additional parameters.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A list of plots.
</p>


</div>