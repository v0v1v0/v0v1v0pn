<div class="container">

<table style="width: 100%;"><tr>
<td>slm</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>slm</h2>

<h3>Description</h3>

<p>The function that returns the left  scalar multiplication
neural network
</p>


<h3>Usage</h3>

<pre><code class="language-R">slm(a, nu)

a %slm% nu
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>a</code></td>
<td>
<p>A real number.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nu</code></td>
<td>
<p>A neural network of the type generated by create_nn().</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>Returns a neural network that is <code class="reqn">a \triangleright \nu</code>. This
instantiates as <code class="reqn">a \cdot f(x)</code> under continuous function activation. More specifically
we define operation as:
</p>
<p>Let <code class="reqn">\lambda \in \mathbb{R}</code>. We will denote by <code class="reqn">(\cdot) \triangleright (\cdot):
\mathbb{R} \times \mathsf{NN} \rightarrow \mathsf{NN}</code> the function satisfying for all
<code class="reqn">\nu \in \mathsf{NN}</code> and <code class="reqn">\lambda \in \mathbb{R}</code> that <code class="reqn">\lambda \triangleright \nu =
\mathsf{Aff}_{\lambda \mathbb{I}_{\mathsf{I}(\nu)},0} \bullet \nu</code>.
</p>


<h3>References</h3>

<p>Definition 2.3.4. Jentzen, A., Kuckuck, B., and von Wurstemberger, P. (2023).
Mathematical introduction to deep learning: Methods, implementations,
and theory. <a href="https://arxiv.org/abs/2310.20360">https://arxiv.org/abs/2310.20360</a>.
</p>
<p><em>Note:</em> We will have two versions of this operation, a prefix and an
infix version.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
5 |&gt; slm(Prd(2.1, 0.1))
Prd(2.1, 0.1) |&gt; srm(5)

</code></pre>


</div>