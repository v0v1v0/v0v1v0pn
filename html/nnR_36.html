<div class="container">

<table style="width: 100%;"><tr>
<td>Pwr</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Pwr</h2>

<h3>Description</h3>

<p>A function that returns the <code class="reqn">\mathsf{Pwr}</code> neural networks.
</p>


<h3>Usage</h3>

<pre><code class="language-R">Pwr(q, eps, exponent)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>q</code></td>
<td>
<p>a real number in <code class="reqn">(2,\infty)</code>. Accuracy as well as computation
time increases as <code class="reqn">q</code> gets closer to <code class="reqn">2</code> increases</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eps</code></td>
<td>
<p>a real number in <code class="reqn">(0,\infty)</code>. ccuracy as well as computation
time increases as <code class="reqn">\varepsilon</code> gets closer to <code class="reqn">0</code> increases</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>exponent</code></td>
<td>
<p>The power to which we will raise. Computation
time increases as exponent increases</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A neural network that approximates raising a number to exponent, when
given appropriate <code class="reqn">q,\varepsilon</code> and exponent when instantiated
under ReLU activation at <code class="reqn">x</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">Pwr(2.1, 0.1, 2) |&gt; inst(ReLU, 3) # This may take some time, please only click once.

</code></pre>


</div>