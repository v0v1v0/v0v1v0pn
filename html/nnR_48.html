<div class="container">

<table style="width: 100%;"><tr>
<td>Tun</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Tun: The function that returns tunneling neural networks</h2>

<h3>Description</h3>

<p>Tun: The function that returns tunneling neural networks
</p>


<h3>Usage</h3>

<pre><code class="language-R">Tun(n, d = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>The depth of the tunnel network where <code class="reqn">n \in \mathbb{N} \cap [1,\infty)</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>d</code></td>
<td>
<p>The dimension of the tunneling network. By default it is assumed to be <code class="reqn">1</code>.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A tunnel neural network of depth n. A tunneling neural
network is defined as the neural network <code class="reqn">\mathsf{Aff}_{1,0}</code> for <code class="reqn">n=1</code>,
the neural network <code class="reqn">\mathsf{Id}_1</code> for <code class="reqn">n=1</code> and the neural network
<code class="reqn">\bullet^{n-2}\mathsf{Id}_1</code> for <code class="reqn">n &gt;2</code>. For this to work we
must provide an appropriate <code class="reqn">n</code> and instantiate with ReLU at some
real number <code class="reqn">x</code>.
</p>


<h3>References</h3>

<p>Definition 2.17. Rafi S., Padgett, J.L., Nakarmi, U. (2024) Towards an Algebraic Framework For
Approximating Functions Using Neural Network Polynomials
<a href="https://arxiv.org/abs/2402.01058">https://arxiv.org/abs/2402.01058</a>
</p>


<h3>Examples</h3>

<pre><code class="language-R">Tun(4)
Tun(4, 3) |&gt; view_nn()

Tun(5)
Tun(5, 3)

</code></pre>


</div>