<div class="container">

<table style="width: 100%;"><tr>
<td>LVQu</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Unsupervised LVQ
</h2>

<h3>Description</h3>

<p>Unsupervised (clustering) Learning Vector Quantization (LVQ) NN.
</p>


<h3>Usage</h3>

<pre><code class="language-R">LVQu(
  data,
  max_number_of_desired_clusters,
  number_of_training_epochs,
  neighborhood_size,
  show_nn )
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>

<p>data to be clustered, a numeric matrix, (2d, cases in rows, variables in columns). By default, initial weights are set to random values in [0 1], so data should also be in 0 to 1 range.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_number_of_desired_clusters</code></td>
<td>

<p>clusters to be produced (at most)
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>number_of_training_epochs</code></td>
<td>

<p>number of training epochs, aka presentations of all training data to ANN during training.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>neighborhood_size</code></td>
<td>

<p>integer &gt;=1, specifies affected neighbor output nodes during training. if 1 (Single Winner) the ANN is somewhat similar to k-means.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>show_nn</code></td>
<td>

<p>boolean, option to display the (trained) ANN internal structure.
</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>Returns a vector of integers containing a cluster id for each data case (row).
</p>


<h3>Note</h3>

<p>Function LVQu employs an unsupervised LVQ for clustering data (Kohonen 1988). This LVQ variant is described as Unsupervised Learning LVQ in Simpson (1991) and is a simplified 1-D version of Self-Organizing-Map (SOM). Its parameter <code>neighborhood_size</code> controls the encoding mode (where <code>neighborhood_size</code>=1 is Single-Winner Unsupervised encoding, similar to k-means, while an odd valued <code>neighborhood_size</code> &gt; 1 means Multiple-Winner Unsupervised encoding mode). Initial weights are random (uniform distribution) in 0 to 1 range. As these weights represent cluster center coordinates (the class reference vector), it is important that input data is also scaled to this range.
</p>
<p>(This function uses Rcpp to employ 'som_nn' class in nnlib2.)
</p>


<h3>Author(s)</h3>

<p>Vasilis N. Nikolaidis &lt;vnnikolaidis@gmail.com&gt;
</p>


<h3>References</h3>

<p>Kohonen, T (1988). Self-Organization and Associative Memory, Springer-Verlag.; Simpson, P. K. (1991). Artificial neural systems: Foundations, paradigms, applications, and implementations. New York: Pergamon Press.
</p>
<p>Philippidis, TP &amp; Nikolaidis, VN &amp; Kolaxis, JG. (1999). Unsupervised pattern recognition techniques for the prediction of composite failure. Journal of acoustic emission. 17. 69-81.
</p>


<h3>See Also</h3>

<p><code>LVQs</code> (supervised LVQ module),
</p>


<h3>Examples</h3>

<pre><code class="language-R"># LVQ expects data in 0 to 1 range, so scale...
iris_s&lt;-as.matrix(iris[1:4])
c_min&lt;-apply(iris_s,2,FUN = "min")
c_max&lt;-apply(iris_s,2,FUN = "max")
c_rng&lt;-c_max-c_min
iris_s&lt;-sweep(iris_s,2,FUN="-",c_min)
iris_s&lt;-sweep(iris_s,2,FUN="/",c_rng)

cluster_ids&lt;-LVQu(iris_s,5,100)
plot(iris_s, pch=cluster_ids, main="LVQ-clustered Iris data")
</code></pre>


</div>