<div class="container">

<table style="width: 100%;"><tr>
<td>LVQs_recall</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
LVQs Helper Function: Classify Data Using Supervised LVQ Code-Book Vectors
</h2>

<h3>Description</h3>

<p>This function simplifies using a Supervised Learning Vector Quantizer Neural Network on data (as compared to using the <code>LVQs</code> module directly). It employs the codebook vector information returned by <code>LVQs_train</code> to assign data to classes.
</p>


<h3>Usage</h3>

<pre><code class="language-R">LVQs_recall(codebook_info,
			data,
			k = 1,
			recall_rewards_limit = 1,
			verbose = FALSE,
			...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>codebook_info</code></td>
<td>

<p>LVQ codebook vector information (as returned by <code>LVQs_train</code>).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>

<p>data to be classified, numeric matrix (2d, cases in rows, variables in columns).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>

<p>number of neighbours (codebook vectors) considered. See <code>help("knn",package = class)</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>recall_rewards_limit</code></td>
<td>

<p>do not use codebook vectors that were rewarded less that this limit during training.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>

<p>show extra information and plots.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>

<p>additional parameters for k-Nearest Neighbour Classification function (<code>class::knn</code>), see <code>help("knn",package = class)</code>.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This is a k-Nearest Neighbor Classifier (employs <code>class::knn</code>), customized for LVQs codebook vectors and related information returned by <code>LVQs_train</code> function.
</p>


<h3>Value</h3>

<p>Factor of classifications ids for <code>data</code> (as returned by function <code>class::knn</code>, see <code>help("knn",package = class)</code>).
</p>


<h3>Author(s)</h3>

<p>Vasilis N. Nikolaidis &lt;vnnikolaidis@gmail.com&gt;
</p>


<h3>References</h3>

<p>Simpson, P. K. (1991). Artificial neural systems: Foundations, paradigms, applications, and implementations. New York: Pergamon Press. p.88.
</p>
<p>Venables, W. N. &amp; Ripley, B. D. (2002) Modern Applied Statistics with S.
Fourth Edition. Springer, New York. ISBN 0-387-95457-0
</p>


<h3>See Also</h3>

<p><code>LVQs_train</code>, <code>LVQs</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># start with the well-know iris dataset:

DATA &lt;- iris[,1:4]
CLASS &lt;- as.factor(iris$Species)

# Randomly split the data into training and testing sets:

indices &lt;- sample(1:nrow(DATA), size = .5 * nrow(DATA))

train_data  &lt;- DATA[indices, ]
train_class &lt;- CLASS[indices]

test_data  &lt;- DATA[-indices, ]
test_class &lt;- CLASS[-indices]

# train LVQ using train data and class:

cv &lt;- LVQs_train(train_data,
				 train_class,
				 number_of_output_nodes_per_class = 4)

# recall (classify) test data:

cl &lt;- LVQs_recall(cv, test_data)

# Compare known and returned test data classifications:

print(table(test_class, cl))
</code></pre>


</div>