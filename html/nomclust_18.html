<div class="container">

<table style="width: 100%;"><tr>
<td>nomclust</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Hierarchical Clustering of Nominal Data</h2>

<h3>Description</h3>

<p>The function performs and evaluates hierarchical cluster analysis of nominal data.
</p>


<h3>Usage</h3>

<pre><code class="language-R">nomclust(
  data,
  measure = "lin",
  method = "average",
  clu.high = 6,
  eval = TRUE,
  prox = 100,
  var.weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>A data.frame or a matrix with cases in rows and variables in columns.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>measure</code></td>
<td>
<p>A character string defining the similarity measure used for computation of proximity matrix in HCA:
<code>"anderberg"</code>, <code>"burnaby"</code>, <code>"eskin"</code>, <code>"gambaryan"</code>, <code>"goodall1"</code>, <code>"goodall2"</code>, <code>"goodall3"</code>, <code>"goodall4"</code>, <code>"iof"</code>, <code>"lin"</code>, <code>"lin1"</code>, <code>"of"</code>, <code>"sm"</code>, <code>"smirnov"</code>, <code>"ve"</code>, <code>"vm"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>A character string defining the clustering method. The following methods can be used: <code>"average"</code>, <code>"complete"</code>, <code>"single"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>clu.high</code></td>
<td>
<p>A numeric value expressing the maximal number of cluster for which the cluster memberships variables are produced.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eval</code></td>
<td>
<p>A logical operator; if TRUE, evaluation of the clustering results is performed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prox</code></td>
<td>
<p>A logical operator or a numeric value. If a logical value TRUE indicates that the proximity matrix is a part of the output. A numeric value (integer) of this argument indicates the maximal number of cases in a dataset for which a proximity matrix will occur in the output.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>var.weights</code></td>
<td>
<p>A numeric vector setting weights to the used variables. One can choose the real numbers from zero to one.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The function runs hierarchical cluster analysis (HCA) with objects characterized by nominal variables (without natural order of categories).
It completely covers the clustering process, from the dissimilarity matrix calculation to the cluster quality evaluation. The function enables a user to choose from the similarity measures for nominal data summarized by (Boriah et al., 2008) and by (Sulc and Rezankova, 2019). 
Next, it offers to choose from three linkage methods that can be used for categorical data. It is also possible to assign user-defined variable weights. The obtained clusters can be evaluated by up to 13 evaluation criteria (Sulc et al., 2018) and (Corter and Gluck, 1992). The output of the nomclust() function may serve as an input for the visualization functions <em>dend.plot</em> and <em>eval.plot</em> in the nomclust package.
</p>


<h3>Value</h3>

<p>The function returns a list with up to six components.
<br><br>
The <code>mem</code> component contains cluster membership partitions for the selected numbers of clusters in the form of a list.
<br><br>
The <code>eval</code> component contains up to 13 evaluation criteria as vectors in a list. Namely, Within-cluster mutability coefficient (WCM), Within-cluster entropy coefficient (WCE),
Pseudo F Indices based on the mutability (PSFM) and the entropy (PSFE), Bayesian (BIC), and Akaike (AIC) information criteria for categorical data, the BK index, Category Utility (CU), Category Information (CI), Hartigan Mutability (HM), Hartigan Entropy (HE) and, if the prox component is present, the silhouette index (SI) and the Dunn index (DI).
<br><br>
The <code>opt</code> component is present in the output together with the <code>eval</code> component. It displays the optimal number of clusters for the evaluation criteria from the <code>eval</code> component, except for WCM and WCE, where the optimal number of clusters is based on the elbow method.
<br><br>
The <code>dend</code> component can be found in the output together with the <code>prox</code> component. It contains all the necessary information for dendrogram creation.
<br><br>
The <code>prox</code> component contains the dissimilarity matrix in the form of the "dist" object.
<br><br>
The <code>call</code> component contains the function call.
</p>


<h3>Author(s)</h3>

<p>Zdenek Sulc. <br> Contact: <a href="mailto:zdenek.sulc@vse.cz">zdenek.sulc@vse.cz</a>
</p>


<h3>References</h3>

<p>Boriah S., Chandola V. and Kumar, V. (2008). Similarity measures for categorical data: A comparative evaluation.
In: Proceedings of the 8th SIAM International Conference on Data Mining, SIAM, p. 243-254.
<br><br>
Corter J.E., Gluck M.A. (1992). Explaining basic categories: Feature predictability and information. Psychological Bulletin 111(2), p. 291â€“303.
<br><br>
Sulc Z., Cibulkova J., Prochazka J., Rezankova H. (2018). Internal Evaluation Criteria for Categorical Data in Hierarchical Clustering: Optimal Number of Clusters Determination, Metodoloski Zveski, 15(2), p. 1-20.
<br><br>
Sulc Z. and Rezankova H. (2019). Comparison of Similarity Measures for Categorical Data in Hierarchical Clustering. Journal of Classification, 35(1), p. 58-72. DOI: 10.1007/s00357-019-09317-5.
</p>


<h3>See Also</h3>

<p><code>evalclust</code>, <code>nomprox</code>, <code>eval.plot</code>, <code>dend.plot</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># sample data
data(data20)

# creating an object with results of hierarchical clustering of 
hca.object &lt;- nomclust(data20, measure = "lin", method = "average",
 clu.high = 5, prox = TRUE)

# assigning variable weights
hca.weights &lt;- nomclust(data20, measure = "lin", method = "average",
 clu.high = 5, prox = TRUE, var.weights = c(0.7, 1, 0.9, 0.5, 0))

# quick clustering summary
summary(hca.object)

# quick cluster quality evaluation
print(hca.object)

# visualization of the evaluation criteria
eval.plot(hca.object)

# a quick dendrogram
plot(hca.object)

# a dendrogram with three designated clusters
dend.plot(hca.object, clusters = 3)

# obtaining values of evaluation indices as a data.frame
data20.eval &lt;- as.data.frame(hca.object$eval)

# getting the optimal numbers of clusters as a data.frame
data20.opt &lt;- as.data.frame(hca.object$opt)

# extracting cluster membership variables as a data.frame
data20.mem &lt;- as.data.frame(hca.object$mem)

# obtaining a proximity matrix
data20.prox &lt;- as.matrix(hca.object$prox)

# setting the maximal number of objects for which a proximity matrix is provided in the output to 30
hca.object &lt;- nomclust(data20, measure = "iof", method = "complete",
 clu.high = 5, prox = 30)
 
# transforming the nomclust object to the class "hclust"
hca.object.hclust &lt;- as.hclust(hca.object)

# transforming the nomclust object to the class "agnes, twins"
hca.object.agnes &lt;- as.agnes(hca.object)


</code></pre>


</div>