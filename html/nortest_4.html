<div class="container">

<table style="width: 100%;"><tr>
<td>pearson.test</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Pearson chi-square test for  normality</h2>

<h3>Description</h3>

<p>Performs the Pearson chi-square test for the composite hypothesis of normality,
see e.g. Thode (2002, Sec. 5.2).
</p>


<h3>Usage</h3>

<pre><code class="language-R">pearson.test(x, n.classes = ceiling(2 * (n^(2/5))), adjust = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>a numeric vector of data values. Missing values are allowed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.classes</code></td>
<td>
<p>The number of classes. The default is due to Moore (1986).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>adjust</code></td>
<td>
<p>logical; if <code>TRUE</code> (default), the p-value is computed from
a chi-square distribution with <code>n.classes</code>-3 degrees of freedom, otherwise
from a chi-square distribution with <code>n.classes</code>-1 degrees of freedom.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The Pearson test statistic is <code class="reqn">P=\sum (C_{i} - E_{i})^{2}/E_{i}</code>,
where <code class="reqn">C_{i}</code> is the number of counted and <code class="reqn">E_{i}</code> is the number of expected observations
(under the hypothesis) in class <code class="reqn">i</code>. The classes are build is such a way that they are equiprobable under the hypothesis
of normality. The p-value is computed from a chi-square distribution with <code>n.classes</code>-3 degrees of freedom
if <code>adjust</code> is <code>TRUE</code> and from a chi-square distribution with <code>n.classes</code>-1
degrees of freedom otherwise. In both cases this is not (!) the correct p-value,
lying somewhere between the two, see also Moore (1986).
</p>


<h3>Value</h3>

<p>A list with class “htest” containing the following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>statistic</code></td>
<td>
<p>the value of the Pearson chi-square statistic.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p.value </code></td>
<td>
<p>the p-value for the test.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>the character string “Pearson chi-square normality test”.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data.name</code></td>
<td>
<p>a character string giving the name(s) of the data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.classes</code></td>
<td>
<p>the number of classes used for the test.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>df</code></td>
<td>
<p>the degress of freedom of the chi-square distribution used to compute the p-value.</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>The Pearson chi-square test is usually not recommended for testing the composite hypothesis of normality
due to its inferior power properties compared to other tests. It is common practice to compute the p-value
from the chi-square distribution with <code>n.classes</code> - 3 degrees of freedom, in order to adjust for the
additional estimation of two parameters. (For the simple hypothesis of normality (mean and variance known)
the test statistic is asymptotically chi-square distributed with
<code>n.classes</code> - 1 degrees of freedom.)
This is, however, not correct as long as the parameters are estimated by <code>mean(x)</code> and <code>var(x)</code>
(or <code>sd(x)</code>), as it is usually done, see Moore (1986) for details.
Since the true p-value is somewhere between the two, it is suggested to run <code>pearson.test</code> twice, with
<code>adjust = TRUE</code> (default) and with <code>adjust = FALSE</code>.
It is also suggested to slightly change the default number of classes, in order
to see the effect on the p-value. Eventually, it is suggested not to rely upon the result of the test.
</p>
<p>The function call <code>pearson.test(x)</code> essentially produces
the same result as the S-PLUS function call <code>chisq.gof((x-mean(x))/sqrt(var(x)), n.param.est=2)</code>.
</p>


<h3>Author(s)</h3>

<p>Juergen Gross</p>


<h3>References</h3>

<p>Moore, D.S. (1986): Tests of the chi-squared type. In:
D'Agostino, R.B. and Stephens, M.A., eds.: Goodness-of-Fit Techniques.
Marcel Dekker, New York.
</p>
<p>Thode Jr., H.C. (2002): Testing for  Normality. Marcel Dekker, New York.
</p>


<h3>See Also</h3>

<p><code>shapiro.test</code> for performing the Shapiro-Wilk test for normality.
<code>ad.test</code>, <code>cvm.test</code>,
<code>lillie.test</code>, <code>sf.test</code> for performing further tests for normality.
<code>qqnorm</code> for producing a normal quantile-quantile plot.</p>


<h3>Examples</h3>

<pre><code class="language-R">pearson.test(rnorm(100, mean = 5, sd = 3))
pearson.test(runif(100, min = 2, max = 4))

</code></pre>


</div>