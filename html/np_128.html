<div class="container">

<table style="width: 100%;"><tr>
<td>npudistbw</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Kernel Distribution Bandwidth Selection with Mixed Data Types</h2>

<h3>Description</h3>

<p><code>npudistbw</code> computes a bandwidth object for a <code class="reqn">p</code>-variate
kernel cumulative distribution estimator defined over mixed continuous
and discrete (ordered) data using either the normal reference
rule-of-thumb or least-squares cross validation using the method of
Li, Li and Racine (2017).
</p>


<h3>Usage</h3>

<pre><code class="language-R">
npudistbw(...)

## S3 method for class 'formula'
npudistbw(formula, data, subset, na.action, call, gdata = NULL,...)

## S3 method for class 'NULL'
npudistbw(dat = stop("invoked without input data 'dat'"),
          bws,
          ...)

## S3 method for class 'dbandwidth'
npudistbw(dat = stop("invoked without input data 'dat'"),
          bws,
          gdat = NULL,
          bandwidth.compute = TRUE,
          nmulti,
          remin = TRUE,
          itmax = 10000,
          do.full.integral = FALSE,
          ngrid = 100,
          ftol = 1.490116e-07,
          tol = 1.490116e-04,
          small = 1.490116e-05,
          lbc.dir = 0.5,
          dfc.dir = 3,
          cfac.dir = 2.5*(3.0-sqrt(5)),
          initc.dir = 1.0,
          lbd.dir = 0.1,
          hbd.dir = 1,
          dfac.dir = 0.25*(3.0-sqrt(5)),
          initd.dir = 1.0,
          lbc.init = 0.1,
          hbc.init = 2.0,
          cfac.init = 0.5,
          lbd.init = 0.1,
          hbd.init = 0.9,
          dfac.init = 0.375, 
          scale.init.categorical.sample = FALSE,
          memfac = 500.0,
          ...)

## Default S3 method:
npudistbw(dat = stop("invoked without input data 'dat'"),
          bws,
          gdat,
          bandwidth.compute = TRUE,
          nmulti,
          remin,
          itmax,
          do.full.integral,
          ngrid,
          ftol,
          tol,
          small,
          lbc.dir,
          dfc.dir,
          cfac.dir,
          initc.dir,
          lbd.dir,
          hbd.dir,
          dfac.dir,
          initd.dir,
          lbc.init,
          hbc.init,
          cfac.init,
          lbd.init,
          hbd.init,
          dfac.init,
          scale.init.categorical.sample,
          memfac,
          bwmethod,
          bwscaling,
          bwtype,
          ckertype,
          ckerorder,
          okertype,
          ...) 

</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>

<p>a symbolic description of variables on which bandwidth selection is
to be performed. The details of constructing a formula are
described below.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>

<p>an optional data frame, list or environment (or object coercible to
a data frame by <code>as.data.frame</code>) containing the
variables in the model. If not found in data, the variables are
taken from <code>environment(formula)</code>, typically the environment
from which the function is called.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subset</code></td>
<td>

<p>an optional vector specifying a subset of observations to be used in
the fitting process. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.action</code></td>
<td>

<p>a function which indicates what should happen when the data contain
<code>NA</code>s. The default is set by the <code>na.action</code> setting
of options, and is <code>na.fail</code> if that is unset. The
(recommended) default is <code>na.omit</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>call</code></td>
<td>

<p>the original function call. This is passed internally by
<code>np</code> when a bandwidth search has been implied by a call to
another function. It is not recommended that the user set this.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gdata</code></td>
<td>

<p>a grid of data on which the indicator function for
least-squares cross-validation is to be computed (can be the sample
or a grid of quantiles).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dat</code></td>
<td>

<p>a <code class="reqn">p</code>-variate data frame on which bandwidth selection will be
performed. The data types may be continuous, discrete (ordered
factors), or some combination thereof.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bws</code></td>
<td>

<p>a bandwidth specification. This can be set as a bandwidth object
returned from a previous invocation, or as a vector of bandwidths,
with each element <code class="reqn">i</code> corresponding to the bandwidth for column
<code class="reqn">i</code> in <code>dat</code>. In either case, the bandwidth supplied will
serve as a starting point in the numerical search for optimal
bandwidths. If specified as a vector, then additional arguments will
need to be supplied as necessary to specify the bandwidth type,
kernel types, selection methods, and so on. This can be left unset.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gdat</code></td>
<td>

<p>a grid of data on which the indicator function for
least-squares cross-validation is to be computed (can be the sample
or a grid of quantiles).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>

<p>additional arguments supplied to specify the bandwidth type,
kernel types, selection methods, and so on, detailed below.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bwmethod</code></td>
<td>
<p> a character string specifying the bandwidth selection
method.  <code>cv.cdf</code> specifies least-squares cross-validation for
cumulative distribution functions (Li, Li and Racine (2017)), and
<code>normal-reference</code> just computes the ‘rule-of-thumb’
bandwidth <code class="reqn">h_j</code> using the standard formula <code class="reqn">h_j =
    1.587 \sigma_j n^{-1/(P+l)}</code>,
where <code class="reqn">\sigma_j</code> is an adaptive measure of spread of
the <code class="reqn">j</code>th continuous variable defined as min(standard deviation,
mean absolute deviation/1.4826, interquartile range/1.349), <code class="reqn">n</code>
the number of observations, <code class="reqn">P</code> the order of the kernel, and
<code class="reqn">l</code> the number of continuous variables. Note that when there
exist factors and the normal-reference rule is used, there is zero
smoothing of the factors. Defaults to <code>cv.cdf</code>.  </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bwscaling</code></td>
<td>
<p> a logical value that when set to <code>TRUE</code> the
supplied bandwidths are interpreted as ‘scale factors’
(<code class="reqn">c_j</code>), otherwise when the value is <code>FALSE</code> they are
interpreted as ‘raw bandwidths’ (<code class="reqn">h_j</code> for continuous data
types, <code class="reqn">\lambda_j</code> for discrete data types). For
continuous data types, <code class="reqn">c_j</code> and <code class="reqn">h_j</code> are
related by the formula <code class="reqn">h_j = c_j \sigma_j n^{-1/(P+l)}</code>, where <code class="reqn">\sigma_j</code> is an
adaptive measure of spread of the <code class="reqn">j</code>th continuous variable
defined as min(standard deviation, mean absolute deviation/1.4826,
interquartile range/1.349), <code class="reqn">n</code> the number of observations,
<code class="reqn">P</code> the order of the kernel, and <code class="reqn">l</code> the number of
continuous variables. For discrete data types, <code class="reqn">c_j</code> and
<code class="reqn">h_j</code> are related by the formula <code class="reqn">h_j =
    c_jn^{-2/(P+l)}</code>, where here <code class="reqn">j</code>
denotes discrete variable <code class="reqn">j</code>.  Defaults to <code>FALSE</code>.  </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bwtype</code></td>
<td>

<p>character string used for the continuous variable bandwidth type,
specifying the type of bandwidth to compute and return in the
<code>bandwidth</code> object. Defaults to <code>fixed</code>. Option
summary:<br><code>fixed</code>: compute fixed bandwidths <br><code>generalized_nn</code>: compute generalized nearest neighbors <br><code>adaptive_nn</code>: compute adaptive nearest neighbors
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bandwidth.compute</code></td>
<td>

<p>a logical value which specifies whether to do a numerical search for
bandwidths or not. If set to <code>FALSE</code>, a <code>bandwidth</code> object
will be returned with bandwidths set to those specified
in <code>bws</code>. Defaults to <code>TRUE</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ckertype</code></td>
<td>

<p>character string used to specify the continuous kernel type.
Can be set as <code>gaussian</code>, <code>epanechnikov</code>, or
<code>uniform</code>. Defaults to <code>gaussian</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ckerorder</code></td>
<td>

<p>numeric value specifying kernel order (one of
<code>(2,4,6,8)</code>). Kernel order specified along with a
<code>uniform</code> continuous kernel type will be ignored. Defaults to
<code>2</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>okertype</code></td>
<td>

<p>character string used to specify the ordered categorical kernel type.
Can be set as <code>wangvanryzin</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nmulti</code></td>
<td>

<p>integer number of times to restart the process of finding extrema of
the cross-validation function from different (random) initial points.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>remin</code></td>
<td>

<p>a logical value which when set as <code>TRUE</code> the search routine
restarts from located minima for a minor gain in accuracy. Defaults
to <code>TRUE</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>itmax</code></td>
<td>

<p>integer number of iterations before failure in the numerical
optimization routine. Defaults to <code>10000</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>do.full.integral</code></td>
<td>

<p>a logical value which when set as <code>TRUE</code> evaluates the
moment-based integral on the entire sample. Defaults
to <code>FALSE</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ngrid</code></td>
<td>

<p>integer number of grid points to use when computing the moment-based
integral. Defaults to <code>100</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ftol</code></td>
<td>

<p>fractional tolerance on the value of the cross-validation function
evaluated at located minima (of order the machine precision or
perhaps slightly larger so as not to be diddled by
roundoff). Defaults to <code>1.490116e-07</code>
(1.0e+01*sqrt(.Machine$double.eps)).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>

<p>tolerance on the position of located minima of the cross-validation
function (tol should generally be no smaller than the square root of
your machine's floating point precision). Defaults to <code>
      1.490116e-04 (1.0e+04*sqrt(.Machine$double.eps))</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>small</code></td>
<td>

<p>a small number used to bracket a minimum (it is hopeless to ask for
a bracketing interval of width less than sqrt(epsilon) times its
central value, a fractional width of only about 10-04 (single
precision) or 3x10-8 (double precision)). Defaults to <code>small
      = 1.490116e-05 (1.0e+03*sqrt(.Machine$double.eps))</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lbc.dir,dfc.dir,cfac.dir,initc.dir</code></td>
<td>
<p> lower bound, chi-square
degrees of freedom, stretch factor, and initial non-random values
for direction set search for Powell's algorithm for <code>numeric</code>
variables. See Details</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lbd.dir,hbd.dir,dfac.dir,initd.dir</code></td>
<td>
<p> lower bound, upper bound,
stretch factor, and initial non-random values for direction set
search for Powell's algorithm for categorical variables. See
Details</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lbc.init, hbc.init, cfac.init</code></td>
<td>
<p> lower bound, upper bound, and
non-random initial values for scale factors for <code>numeric</code>
variables for Powell's algorithm. See Details</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lbd.init, hbd.init, dfac.init</code></td>
<td>
<p> lower bound, upper bound, and
non-random initial values for scale factors for categorical
variables for Powell's algorithm. See Details</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale.init.categorical.sample</code></td>
<td>
<p> a logical value that when set
to <code>TRUE</code> scales <code>lbd.dir</code>, <code>hbd.dir</code>,
<code>dfac.dir</code>, and <code>initd.dir</code> by <code class="reqn">n^{-2/(2P+l)}</code>,
<code class="reqn">n</code> the number of observations, <code class="reqn">P</code> the order of the
kernel, and <code class="reqn">l</code> the number of <code>numeric</code> variables. See
Details</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>memfac</code></td>
<td>

<p>The algorithm to compute the least-squares objective function uses
a block-based algorithm to eliminate or minimize redundant kernel
evaluations. Due to memory, hardware and software constraints, a
maximum block size must be imposed by the algorithm. This block size
is roughly equal to memfac*10^5 elements. Empirical tests on
modern hardware find that a memfac of 500 performs well. If
you experience out of memory errors, or strange behaviour for
large data sets (&gt;100k elements) setting memfac to a lower value may
fix the problem.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Typical usages are (see below for a complete list of options and also
the examples at the end of this help file)
</p>
<pre>
    
    Usage 1: compute a bandwidth object using the formula interface:
    
    bw &lt;- npudistbw(~y)
    
    Usage 2: compute a bandwidth object using the data frame interface
    and change the default kernel and order:

    Fhat &lt;- npudistbw(tdat = y, ckertype="epanechnikov", ckerorder=4)
    
  </pre>
<p><code>npudistbw</code> implements a variety of methods for choosing
bandwidths for multivariate (<code class="reqn">p</code>-variate) distributions defined
over a set of possibly continuous and/or discrete (ordered) data. The
approach is based on Li and Racine (2003) who employ
‘generalized product kernels’ that admit a mix of continuous
and discrete data types.
</p>
<p>The cross-validation methods employ multivariate numerical search
algorithms (direction set (Powell's) methods in multidimensions).
</p>
<p>Bandwidths can (and will) differ for each variable which is, of
course, desirable.
</p>
<p>Three classes of kernel estimators for the continuous data types are
available: fixed, adaptive nearest-neighbor, and generalized
nearest-neighbor. Adaptive nearest-neighbor bandwidths change with
each sample realization in the set, <code class="reqn">x_i</code>, when estimating the
cumulative distribution at the point <code class="reqn">x</code>. Generalized nearest-neighbor bandwidths change
with the point at which the cumulative distribution is estimated, <code class="reqn">x</code>. Fixed bandwidths
are constant over the support of <code class="reqn">x</code>.
</p>
<p><code>npudistbw</code> may be invoked <em>either</em> with a formula-like
symbolic description of variables on which bandwidth selection is to
be performed <em>or</em> through a simpler interface whereby data is
passed directly to the function via the <code>dat</code> parameter. Use of
these two interfaces is <b>mutually exclusive</b>.
</p>
<p>Data contained in the data frame <code>dat</code> may be a mix of continuous
(default) and ordered discrete (to be specified in the data frame
<code>dat</code> using <code>ordered</code>). Data can be entered in an
arbitrary order and data types will be detected automatically by the
routine (see <code>np</code> for details).
</p>
<p>Data for which bandwidths are to be estimated may be specified
symbolically. A typical description has the form <code>~ data</code>, where
<code>data</code> is a series of variables specified by name, separated by
the separation character '+'. For example, <code> ~ x + y </code> specifies
that the bandwidths for the joint distribution of variables <code>x</code>
and <code>y</code> are to be estimated. See below for further examples.
</p>
<p>A variety of kernels may be specified by the user. Kernels implemented
for continuous data types include the second, fourth, sixth, and
eighth-order Gaussian and Epanechnikov kernels, and the uniform
kernel. Ordered data types use a variation of the Wang and van Ryzin
(1981) kernel.
</p>
<p>The optimizer invoked for search is Powell's conjugate direction
method which requires the setting of (non-random) initial values and
search directions for bandwidths, and when restarting, random values
for successive invocations. Bandwidths for <code>numeric</code> variables
are scaled by robust measures of spread, the sample size, and the
number of <code>numeric</code> variables where appropriate. Two sets of
parameters for bandwidths for <code>numeric</code> can be modified, those
for initial values for the parameters themselves, and those for the
directions taken (Powell's algorithm does not involve explicit
computation of the function's gradient). The default values are set by
considering search performance for a variety of difficult test cases
and simulated cases. We highly recommend restarting search a large
number of times to avoid the presence of local minima (achieved by
modifying <code>nmulti</code>). Further refinement for difficult cases can
be achieved by modifying these sets of parameters. However, these
parameters are intended more for the authors of the package to enable
‘tuning’ for various methods rather than for the user them
self.
</p>


<h3>Value</h3>

<p><code>npudistbw</code> returns a <code>bandwidth</code> object with the
following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>bw</code></td>
<td>
<p> bandwidth(s), scale factor(s) or nearest neighbours for the
data, <code>dat</code> </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fval</code></td>
<td>
<p> objective function value at minimum </p>
</td>
</tr>
</table>
<p>if <code>bwtype</code> is set to <code>fixed</code>, an object containing
bandwidths, of class <code>bandwidth</code>
(or scale factors if <code>bwscaling = TRUE</code>) is returned. If it is set to
<code>generalized_nn</code> or <code>adaptive_nn</code>, then instead the
<code class="reqn">k</code>th nearest 
neighbors are returned for the continuous variables while the discrete
kernel bandwidths are returned for the discrete variables. Bandwidths
are stored under the component name <code>bw</code>, with each
element <code class="reqn">i</code> corresponding to column <code class="reqn">i</code> of input data
<code>dat</code>.
</p>
<p>The functions  <code>predict</code>, <code>summary</code> and <code>plot</code> support
objects of type <code>bandwidth</code>.
</p>


<h3>Usage Issues</h3>

<p>If you are using data of mixed types, then it is advisable to use the
<code>data.frame</code> function to construct your input data and not
<code>cbind</code>, since <code>cbind</code> will typically not work as
intended on mixed data types and will coerce the data to the same
type.
</p>
<p>Caution: multivariate data-driven bandwidth selection methods are, by
their nature, <em>computationally intensive</em>. Virtually all methods
require dropping the <code class="reqn">i</code>th observation from the data set, computing an
object, repeating this for all observations in the sample, then
averaging each of these leave-one-out estimates for a <em>given</em>
value of the bandwidth vector, and only then repeating this a large
number of times in order to conduct multivariate numerical
minimization/maximization. Furthermore, due to the potential for local
minima/maxima, <em>restarting this procedure a large number of times may
often be necessary</em>. This can be frustrating for users possessing
large datasets. For exploratory purposes, you may wish to override the
default search tolerances, say, setting ftol=.01 and tol=.01 and
conduct multistarting (the default is to restart min(5, ncol(dat))
times) as is done for a number of examples. Once the procedure
terminates, you can restart search with default tolerances using those
bandwidths obtained from the less rigorous search (i.e., set
<code>bws=bw</code> on subsequent calls to this routine where <code>bw</code> is
the initial bandwidth object).  A version of this package using the
<code>Rmpi</code> wrapper is under development that allows one to deploy
this software in a clustered computing environment to facilitate
computation involving large datasets.
</p>


<h3>Author(s)</h3>

<p>Tristen Hayfield <a href="mailto:tristen.hayfield@gmail.com">tristen.hayfield@gmail.com</a>, Jeffrey S. Racine
<a href="mailto:racinej@mcmaster.ca">racinej@mcmaster.ca</a>
</p>


<h3>References</h3>

<p>Aitchison, J. and C.G.G. Aitken (1976), “Multivariate binary
discrimination by the kernel method,” Biometrika, 63, 413-420.
</p>
<p>Bowman, A. and P. Hall and T. Prvan (1998), “Bandwidth
selection for the smoothing of distribution functions,” Biometrika,
85, 799-808.
</p>
<p>Li, Q. and J.S. Racine (2007), <em>Nonparametric Econometrics: Theory
and Practice,</em> Princeton University Press.
</p>
<p>Li, Q. and J.S. Racine (2003), “Nonparametric estimation of
distributions with categorical and continuous data,” Journal
of Multivariate Analysis, 86, 266-292.
</p>
<p>Li, C. and H. Li and J.S. Racine (2017), “Cross-Validated Mixed
Datatype Bandwidth Selection for Nonparametric Cumulative
Distribution/Survivor Functions,” Econometric Reviews, <b>36</b>,
970-987.
</p>
<p>Ouyang, D. and Q. Li and J.S. Racine (2006), “Cross-validation
and the estimation of probability distributions with categorical
data,” Journal of Nonparametric Statistics, 18, 69-100.
</p>
<p>Pagan, A. and A. Ullah (1999), <em>Nonparametric Econometrics,</em>
Cambridge University Press.
</p>
<p>Scott, D.W. (1992), <em>Multivariate Cumulative Distribution
Estimation: Theory, Practice and Visualization,</em> New York: Wiley.
</p>
<p>Silverman, B.W. (1986), <em>Density Estimation,</em> London: Chapman and
Hall.
</p>
<p>Wang, M.C. and J. van Ryzin (1981), “A class of smooth estimators
for discrete distributions,”  Biometrika, 68, 301-309.
</p>


<h3>See Also</h3>

<p><code>bw.nrd</code>, <code>bw.SJ</code>,  <code>hist</code>,
<code>npudist</code>, <code>npudist</code> </p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
# EXAMPLE 1 (INTERFACE=FORMULA): For this example, we load Giovanni
# Baiocchi's Italian GDP panel (see Italy for details), then create a
# data frame in which year is an ordered factor, GDP is continuous.

data("Italy")
attach(Italy)

data &lt;- data.frame(ordered(year), gdp)

# We compute bandwidths for the kernel cumulative distribution estimator
# using the normal-reference rule-of-thumb. Otherwise, we use the
# defaults (second order Gaussian kernel, fixed bandwidths). Note that
# the bandwidth object you compute inherits all properties of the
# estimator (kernel type, kernel order, estimation method) and can be
# fed directly into the plotting utility plot() or into the npudist()
# function.

bw &lt;- npudistbw(formula=~ordered(year)+gdp, bwmethod="normal-reference")

summary(bw)

# Sleep for 5 seconds so that we can examine the output...

Sys.sleep(5)

# Next, specify a value for the bandwidths manually (0.5 for the first
# variable, 1.0 for the second)...

bw &lt;- npudistbw(formula=~ordered(year)+gdp, bws=c(0.5, 1.0),
                bandwidth.compute=FALSE)

summary(bw)

# Sleep for 5 seconds so that we can examine the output...

Sys.sleep(5)

# Next, if you wanted to use the 1.587 sigma n^{-1/(2p+q)} rule-of-thumb
# for the bandwidth for the continuous variable and, say, no smoothing
# for the discrete variable, you would use the bwscaling=TRUE argument
# and feed in the values 0 for the first variable (year) and 1.587 for
# the second (gdp). Note that in the printout it reports the `scale
# factors' rather than the `bandwidth' as reported in some of the
# previous examples.

bw &lt;- npudistbw(formula=~ordered(year)+gdp, bws=c(0, 1.587),
                bwscaling=TRUE, 
                bandwidth.compute=FALSE)

summary(bw)

# Sleep for 5 seconds so that we can examine the output...

Sys.sleep(5)

# If you wished to use, say, an eighth-order Epanechnikov kernel for the
# continuous variables and specify your own bandwidths, you could do
# that as follows.

bw &lt;- npudistbw(formula=~ordered(year)+gdp, bws=c(0.5, 1.0),
                bandwidth.compute=FALSE, 
                ckertype="epanechnikov",
                ckerorder=8)

summary(bw)

# Sleep for 5 seconds so that we can examine the output...

Sys.sleep(5)

# If you preferred, say, nearest-neighbor bandwidths and a generalized
# kernel estimator for the continuous variable, you would use the
# bwtype="generalized_nn" argument.

bw &lt;- npudistbw(formula=~ordered(year)+gdp, bwtype = "generalized_nn")

summary(bw)

# Sleep for 5 seconds so that we can examine the output...

Sys.sleep(5)

# Next, compute bandwidths using cross-validation, fixed bandwidths, and
# a second-order Gaussian kernel for the continuous variable (default).
# Note - this may take a few minutes depending on the speed of your
# computer.

bw &lt;- npudistbw(formula=~ordered(year)+gdp)

summary(bw)

# Sleep for 5 seconds so that we can examine the output...

Sys.sleep(5)

# Finally, if you wish to use initial values for numerical search, you
# can either provide a vector of bandwidths as in bws=c(...) or a
# bandwidth object from a previous run, as in

bw &lt;- npudistbw(formula=~ordered(year)+gdp, bws=c(1, 1))

summary(bw)

detach(Italy)

# EXAMPLE 1 (INTERFACE=DATA FRAME): For this example, we load Giovanni
# Baiocchi's Italian GDP panel (see Italy for details), then create a
# data frame in which year is an ordered factor, GDP is continuous.

data("Italy")
attach(Italy)

data &lt;- data.frame(ordered(year), gdp)

# We compute bandwidths for the kernel cumulative distribution estimator
# using the normal-reference rule-of-thumb. Otherwise, we use the
# defaults (second-order Gaussian kernel, fixed bandwidths). Note that
# the bandwidth object you compute inherits all properties of the
# estimator (kernel type, kernel order, estimation method) and can be
# fed directly into the plotting utility plot() or into the npudist()
# function.

bw &lt;- npudistbw(dat=data, bwmethod="normal-reference")

summary(bw)

# Sleep for 5 seconds so that we can examine the output...

Sys.sleep(5)

# Next, specify a value for the bandwidths manually (0.5 for the first
# variable, 1.0 for the second)...

bw &lt;- npudistbw(dat=data, bws=c(0.5, 1.0), bandwidth.compute=FALSE)

summary(bw)

# Sleep for 5 seconds so that we can examine the output...

Sys.sleep(5)

# Next, if you wanted to use the 1.587 sigma n^{-1/(2p+q)} rule-of-thumb
# for the bandwidth for the continuous variable and, say, no smoothing
# for the discrete variable, you would use the bwscaling=TRUE argument
# and feed in the values 0 for the first variable (year) and 1.587 for
# the second (gdp). Note that in the printout it reports the `scale
# factors' rather than the `bandwidth' as reported in some of the
# previous examples.

bw &lt;- npudistbw(dat=data, bws=c(0, 1.587),
                bwscaling=TRUE, 
                bandwidth.compute=FALSE)

summary(bw)

# Sleep for 5 seconds so that we can examine the output...

Sys.sleep(5)

# If you wished to use, say, an eighth-order Epanechnikov kernel for the
# continuous variables and specify your own bandwidths, you could do
# that as follows:

bw &lt;- npudistbw(dat=data, bws=c(0.5, 1.0),
                bandwidth.compute=FALSE, 
                ckertype="epanechnikov",
                ckerorder=8)

summary(bw)

# Sleep for 5 seconds so that we can examine the output...

Sys.sleep(5)

# If you preferred, say, nearest-neighbor bandwidths and a generalized
# kernel estimator for the continuous variable, you would use the
# bwtype="generalized_nn" argument.

bw &lt;- npudistbw(dat=data, bwtype = "generalized_nn")

summary(bw)

# Sleep for 5 seconds so that we can examine the output...

Sys.sleep(5)

# Next, compute bandwidths using cross-validation, fixed bandwidths, and
# a second order Gaussian kernel for the continuous variable (default).
# Note - this may take a few minutes depending on the speed of your
# computer.

bw &lt;- npudistbw(dat=data)

summary(bw)

# Sleep for 5 seconds so that we can examine the output...

Sys.sleep(5)

# Finally, if you wish to use initial values for numerical search, you
# can either provide a vector of bandwidths as in bws=c(...) or a
# bandwidth object from a previous run, as in

bw &lt;- npudistbw(dat=data, bws=c(1, 1))

summary(bw)

detach(Italy)

## End(Not run) 
</code></pre>


</div>