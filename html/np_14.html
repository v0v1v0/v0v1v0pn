<div class="container">

<table style="width: 100%;"><tr>
<td>np</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Nonparametric Kernel Smoothing Methods for Mixed Data Types</h2>

<h3>Description</h3>

<p>This package provides a variety of nonparametric and semiparametric
kernel methods that seamlessly handle a mix of continuous, unordered,
and ordered factor data types (unordered and ordered factors are often
referred to as ‘nominal’ and ‘ordinal’ categorical
variables respectively). A vignette containing many of the examples
found in the help files accompanying the <span class="pkg">np</span> package that is
intended to serve as a gentle introduction to this package can be
accessed via <code>vignette("np", package="np")</code>.
</p>
<p>For a listing of all routines in the <span class="pkg">np</span> package type:
‘library(help="np")’.  
</p>
<p>Bandwidth selection is a key aspect of sound nonparametric and
semiparametric kernel estimation. <code>np</code> is designed from the
ground up to make bandwidth selection the focus of attention. To this
end, one typically begins by creating a ‘bandwidth object’
which embodies all aspects of the method, including specific kernel
functions, data names, data types, and the like. One then passes these
bandwidth objects to other functions, and those functions can grab the
specifics from the bandwidth object thereby removing potential
inconsistencies and unnecessary repetition. Furthermore, many
functions such as <code>plot</code> (which automatically calls
<code>npplot</code>) can work with the bandwidth object directly without
having to do the subsequent companion function evaluation.
</p>
<p>As of <code>np</code> version 0.20-0, we allow the user to combine these
steps. When using <code>np</code> versions 0.20-0 and higher, if the first
step (bandwidth selection) is not performed explicitly then the second
step will automatically call the omitted first step bandwidth selector
using defaults unless otherwise specified, and the bandwidth object
could then be retrieved retroactively if so desired via
<code>objectname$bws</code>. Furthermore, options for bandwidth selection
will be passed directly to the bandwidth selector function. Note that
the combined approach would not be a wise choice for certain
applications such as when bootstrapping (as it would involve
unnecessary computation since the bandwidths would properly be those
for the original sample and not the bootstrap resamples) or when
conducting quantile regression (as it would involve unnecessary
computation when different quantiles are computed from the same
conditional cumulative distribution estimate).
</p>
<p>There are two ways in which you can interact with functions in
<code>np</code>, either i) using data frames, or ii) using a formula
interface, where appropriate.
</p>
<p>To some, it may be natural to use the data frame interface.  The R
<code>data.frame</code> function preserves a variable's type once it
has been cast (unlike <code>cbind</code>, which we avoid for this
reason).  If you find this most natural for your project, you first
create a data frame casting data according to their type (i.e., one of
continuous (default, <code>numeric</code>), <code>factor</code>,
<code>ordered</code>). Then you would simply pass this data frame to
the appropriate <code>np</code> function, for example
<code>npudensbw(dat=data)</code>.
</p>
<p>To others, however, it may be natural to use the formula interface
that is used for the regression examples, among others. For
nonparametric regression functions such as <code>npreg</code>, you
would proceed as you would using <code>lm</code> (e.g., <code>bw &lt;-
  npregbw(y~factor(x1)+x2))</code> except that you would of course not need to
specify, e.g., polynomials in variables, interaction terms, or create
a number of dummy variables for a factor.  Every function in np
supports both interfaces, where appropriate.
</p>
<p>Note that if your factor is in fact a character string such as, say,
<code>X</code> being either <code>"MALE"</code> or <code>"FEMALE"</code>, np will handle
this directly, i.e., there is no need to map the string values into
unique integers such as (0,1). Once the user casts a variable as a
particular data type (i.e., <code>factor</code>,
<code>ordered</code>, or continuous (default,
<code>numeric</code>)), all subsequent methods automatically detect
the type and use the appropriate kernel function and method where
appropriate.
</p>
<p>All estimation methods are fully multivariate, i.e., there are no
limitations on the number of variables one can model (or number of
observations for that matter). Execution time for most routines is,
however, exponentially increasing in the number of observations and
increases with the number of variables involved.
</p>
<p>Nonparametric methods include unconditional density (distribution),
conditional density (distribution), regression, mode, and quantile
estimators along with gradients where appropriate, while
semiparametric methods include single index, partially linear, and
smooth (i.e., varying) coefficient models.
</p>
<p>A number of tests are included such as consistent specification tests
for parametric regression and quantile regression models along with
tests of significance for nonparametric regression.
</p>
<p>A variety of bootstrap methods for computing standard errors,
nonparametric confidence bounds, and bias-corrected bounds are
implemented.
</p>
<p>A variety of bandwidth methods are implemented including fixed,
nearest-neighbor, and adaptive nearest-neighbor.
</p>
<p>A variety of data-driven methods of bandwidth selection are
implemented, while the user can specify their own bandwidths should
they so choose (either a raw bandwidth or scaling factor).
</p>
<p>A flexible plotting utility, <code>npplot</code> (which is
automatically invoked by <code>plot</code>) , facilitates graphing of
multivariate objects. An example for creating postscript graphs using
the <code>npplot</code> utility and pulling this into a LaTeX
document is provided.
</p>
<p>The function <code>npksum</code> allows users to create or implement
their own kernel estimators or tests should they so desire.
</p>
<p>The underlying functions are written in C for computational
efficiency. Despite this, due to their nature, data-driven bandwidth
selection methods involving multivariate numerical search can be
time-consuming, particularly for large datasets. A version of this
package using the <code>Rmpi</code> wrapper is under development that allows
one to deploy this software in a clustered computing environment to
facilitate computation involving large datasets.
</p>
<p>To cite the <code>np</code> package, type <code>citation("np")</code> from within
<code>R</code> for details.
</p>


<h3>Details</h3>

<p> The kernel methods in <code>np</code> employ the so-called
‘generalized product kernels’ found in Hall, Racine,
and Li (2004), Li, Lin, and Racine (2013), Li, Ouyang, and
Racine (2013), Li and Racine (2003), Li and Racine (2004), Li
and Racine (2007), Li and Racine (2010), Ouyang, Li, and
Racine (2006), and Racine and Li (2004), among others. For
details on a particular method, kindly refer to the original
references listed above.
</p>
<p>We briefly describe the particulars of various univariate kernels used
to generate the generalized product kernels that underlie the kernel
estimators implemented in the <code>np</code> package. In a nutshell, the
generalized kernel functions that underlie the kernel estimators in
<code>np</code> are formed by taking the product of univariate kernels such
as those listed below. When you cast your data as a particular type
(continuous, factor, or ordered factor) in a data frame or formula,
the routines will automatically recognize the type of variable being
modelled and use the appropriate kernel type for each variable in the
resulting estimator.
</p>

<dl>
<dt>Second Order Gaussian (<code class="reqn">x</code> is continuous)</dt>
<dd>
<p><code class="reqn">k(z) = \exp(-z^2/2)/\sqrt{2\pi}</code> where <code class="reqn">z=(x_i-x)/h</code>,
and <code class="reqn">h&gt;0</code>.
</p>
</dd>
<dt>Second Order Truncated Gaussian (<code class="reqn">x</code> is continuous)</dt>
<dd>
<p><code class="reqn">k(z) = (\exp(-z^2/2)-\exp(-b^2/2))/(\textrm{erf}(b/\sqrt{2})\sqrt{2\pi}-2b\exp(-b^2/2))</code> where <code class="reqn">z=(x_i-x)/h</code>, <code class="reqn">b&gt;0</code>, <code class="reqn">|z|\le b</code>
and <code class="reqn">h&gt;0</code>.
</p>
<p>See <code>nptgauss</code> for details on modifying <code class="reqn">b</code>.
</p>
</dd>
<dt>Second Order Epanechnikov (<code class="reqn">x</code> is continuous)</dt>
<dd>
<p><code class="reqn">k(z) =  3\left(1 - z^2/5\right)/(4\sqrt{5})</code>
if <code class="reqn">z^2&lt;5</code>, <code class="reqn">0</code> otherwise, where
<code class="reqn">z=(x_i-x)/h</code>, and <code class="reqn">h&gt;0</code>.
</p>
</dd>
<dt>Uniform (<code class="reqn">x</code> is continuous)</dt>
<dd>
<p><code class="reqn">k(z) = 1/2</code> if <code class="reqn">|z|&lt;1</code>, <code class="reqn">0</code> otherwise, where
<code class="reqn">z=(x_i-x)/h</code>, and <code class="reqn">h&gt;0</code>.
</p>
</dd>
<dt>Aitchison and Aitken (<code class="reqn">x</code> is a (discrete) factor)</dt>
<dd>
<p><code class="reqn">l(x_i,x,\lambda) = 1 - \lambda</code> if <code class="reqn">x_i=x</code>, and
<code class="reqn">\lambda/(c-1)</code> if <code class="reqn">x_i \neq x</code>,
where <code class="reqn">c</code> is the number of (discrete) outcomes assumed by the
factor <code class="reqn">x</code>.
</p>
<p>Note that <code class="reqn">\lambda</code> must lie between <code class="reqn">0</code> and
<code class="reqn">(c-1)/c</code>.
</p>
</dd>
<dt>Wang and van Ryzin (<code class="reqn">x</code> is a (discrete) ordered factor)</dt>
<dd>
<p><code class="reqn">l(x_i,x,\lambda) = 1 - \lambda</code> if <code class="reqn">|x_i-x|=0</code>, and
<code class="reqn">((1-\lambda)/2)\lambda^{|x_i-x|}</code>
if <code class="reqn">|x_i - x|\ge1</code>.
</p>
<p>Note that <code class="reqn">\lambda</code> must lie between <code class="reqn">0</code> and
<code class="reqn">1</code>.
</p>
</dd>
<dt>Li and Racine (<code class="reqn">x</code> is a (discrete) factor)</dt>
<dd>
<p><code class="reqn">l(x_i,x,\lambda) = 1 </code> if <code class="reqn">x_i=x</code>, and
<code class="reqn">\lambda</code> if <code class="reqn">x_i \neq x</code>.
</p>
<p>Note that <code class="reqn">\lambda</code> must lie between <code class="reqn">0</code> and
<code class="reqn">1</code>.
</p>
</dd>
<dt>Li and Racine Normalised for Unconditional Objects (<code class="reqn">x</code> is a (discrete) factor)</dt>
<dd>
<p><code class="reqn">l(x_i,x,\lambda) = 1/(1+(c-1)\lambda) </code> if <code class="reqn">x_i=x</code>, and
<code class="reqn">\lambda/(1+(c-1)\lambda)</code> if <code class="reqn">x_i \neq x</code>.
</p>
<p>Note that <code class="reqn">\lambda</code> must lie between <code class="reqn">0</code> and
<code class="reqn">1</code>.
</p>
</dd>
<dt>Li and Racine (<code class="reqn">x</code> is a (discrete) ordered factor)</dt>
<dd>
<p><code class="reqn">l(x_i,x,\lambda) = 1</code> if
<code class="reqn">|x_i-x|=0</code>, and
<code class="reqn">\lambda^{|x_i-x|}</code> if <code class="reqn">|x_i -
        x|\ge1</code>.
</p>
<p>Note that <code class="reqn">\lambda</code> must lie between <code class="reqn">0</code> and
<code class="reqn">1</code>.
</p>
</dd>
<dt>Li and Racine Normalised for Unconditional Objects (<code class="reqn">x</code> is a (discrete) ordered factor)</dt>
<dd>
<p><code class="reqn">l(x_i,x,\lambda) = (1-\lambda)/(1+\lambda)</code> if
<code class="reqn">|x_i-x|=0</code>, and
<code class="reqn">(1-\lambda)/(1+\lambda)\lambda^{|x_i-x|}</code> if <code class="reqn">|x_i -
        x|\ge1</code>.
</p>
<p>Note that <code class="reqn">\lambda</code> must lie between <code class="reqn">0</code> and
<code class="reqn">1</code>.
</p>
</dd>
</dl>
<p>So, if you had two variables, <code class="reqn">x_{i1}</code> and
<code class="reqn">x_{i2}</code>, and <code class="reqn">x_{i1}</code> was continuous while
<code class="reqn">x_{i2}</code> was, say, binary (0/1), and you created a data
frame of the form <code>X &lt;- data.frame(x1,x2=factor(x2))</code>, then the
kernel function used by <code>np</code> would be
<code class="reqn">K(\cdot)=k(\cdot)\times l(\cdot)</code> where the
particular kernel functions <code class="reqn">k(\cdot)</code> and
<code class="reqn">l(\cdot)</code> would be, say, the second order Gaussian
(<code>ckertype="gaussian"</code>) and Aitchison and Aitken
(<code>ukertype="aitchisonaitken"</code>) kernels by default, respectively
(note that for conditional density and distribution objects we can
specify kernels for the left-hand side and right-hand side variables
in this manner using <code>cykertype="gaussian"</code>,
<code>cxkertype="gaussian"</code> and <code>uykertype="aitchisonaitken"</code>,
<code>uxkertype="aitchisonaitken"</code>).
</p>
<p>Note that higher order continuous kernels (i.e., fourth, sixth, and
eighth order) are derived from the second order kernels given above
(see Li and Racine (2007) for details).
</p>
<p>For particulars on any given method, kindly see the references listed
for the method in question.
</p>


<h3>Author(s)</h3>

<p>Tristen Hayfield &lt;tristen.hayfield@gmail.com&gt;, Jeffrey S. Racine
&lt;racinej@mcmaster.ca&gt;
</p>
<p>Maintainer: Jeffrey S. Racine &lt;racinej@mcmaster.ca&gt;
</p>
<p>We are grateful to John Fox and Achim Zeleis for their valuable input
and encouragement. We would like to gratefully acknowledge support
from the Natural Sciences and Engineering Research Council of Canada
(NSERC:www.nserc.ca), the Social Sciences and Humanities Research
Council of Canada (SSHRC:www.sshrc.ca), and the Shared Hierarchical
Academic Research Computing Network (SHARCNET:www.sharcnet.ca)
</p>


<h3>References</h3>

<p>Aitchison, J. and C.G.G. Aitken (1976), “Multivariate binary
discrimination by the kernel method,” Biometrika, 63, 413-420.
</p>
<p>Hall, P. and J.S. Racine and Q. Li (2004), “Cross-validation
and the estimation of conditional probability densities,” Journal of
the American Statistical Association, 99, 1015-1026.
</p>
<p>Li, Q. and J. Lin and J.S. Racine (2013), “Optimal bandwidth
selection for nonparametric conditional distribution and quantile
functions”, Journal of Business and Economic Statistics, 31, 57-65.
</p>
<p>Li, Q. and D. Ouyang and J.S. Racine (2013), “Categorical
Semiparametric Varying-Coefficient Models,” Journal of Applied
Econometrics, 28, 551-589.
</p>
<p>Li, Q. and J.S. Racine (2003), “Nonparametric estimation of
distributions with categorical and continuous data,” Journal of
Multivariate Analysis, 86, 266-292.
</p>
<p>Li, Q. and J.S. Racine (2004), “Cross-validated local linear
nonparametric regression,” Statistica Sinica, 14, 485-512.
</p>
<p>Li, Q. and J.S. Racine (2007), <em>Nonparametric Econometrics:
Theory and Practice,</em> Princeton University Press.
</p>
<p>Li, Q. and J.S. Racine (2010), “Smooth varying-coefficient
estimation and inference for qualitative and quantitative data,”
Econometric Theory, 26, 1-31.
</p>
<p>Ouyang, D. and Q. Li and J.S. Racine (2006), “Cross-validation
and the estimation of probability distributions with categorical
data,” Journal of Nonparametric Statistics, 18, 69-100.
</p>
<p>Racine, J.S. and Q. Li (2004), “Nonparametric estimation of
regression functions with both categorical and continuous data,”
Journal of Econometrics, 119, 99-130.
</p>
<p>Pagan, A. and A. Ullah (1999), <em>Nonparametric Econometrics,</em>
Cambridge University Press.
</p>
<p>Scott, D.W. (1992), <em>Multivariate Density Estimation: Theory,
Practice and Visualization,</em> New York: Wiley.
</p>
<p>Silverman, B.W. (1986), <em>Density Estimation,</em> London: Chapman and
Hall.
</p>
<p>Wang, M.C. and J. van Ryzin (1981), “A class of smooth
estimators for discrete distributions,” Biometrika, 68, 301-309.
</p>


</div>