<div class="container">

<table style="width: 100%;"><tr>
<td>summary</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Summary methods for Fit Models
</h2>

<h3>Description</h3>

<p><code>summary</code> methods for object classes "gsm", "sm", and "ss".
</p>


<h3>Usage</h3>

<pre><code class="language-R">## S3 method for class 'gsm'
summary(object, ...)

## S3 method for class 'sm'
summary(object, ...)

## S3 method for class 'ss'
summary(object, ...)

## S3 method for class 'summary.gsm'
print(x, digits = max(3, getOption("digits") - 3), 
      signif.stars = getOption("show.signif.stars"), ...)

## S3 method for class 'summary.sm'
print(x, digits = max(3, getOption("digits") - 3), 
      signif.stars = getOption("show.signif.stars"), ...)

## S3 method for class 'summary.ss'
print(x, digits = max(3, getOption("digits") - 3), 
      signif.stars = getOption("show.signif.stars"), ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>

<p>an object of class "gsm" output by the <code>gsm</code> function, "sm" output by the <code>sm</code> function, or "ss" output by the <code>ss</code> function
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>an object of class "summary.gsm" output by the <code>summary.gsm</code> function, "summary.sm" output by the <code>summary.sm</code> function, or "summary.ss" output by the <code>summary.ss</code> function.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>digits</code></td>
<td>

<p>the minimum number of significant digits to be printed in values.  
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>signif.stars</code></td>
<td>

<p>logical. If <code>TRUE</code>, ‘significance stars’ are printed for each coefficient.  
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>

<p>additional arguments affecting the summary produced (currently ignored).
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Summary includes information for assessing the statistical and practical significance of the model terms. 
</p>
<p>Statistical inference is conducted via (approximate) frequentist chi-square tests using the Bayesian interpretation of a smoothing spline (Nychka, 1988; Wahba, 1983). 
</p>
<p>With multiple smooth terms included in the model, the inferential results may (and likely will) differ slightly depending on the <code>tprk</code> argument (when using the <code>gsm</code> and <code>sm</code> functions). 
</p>
<p>If significance testing is of interest, the <code>tprk = FALSE</code> option may be desirable, given that this allows for unique basis function coefficients for each model term.
</p>
<p>In all cases, the inferential results are based on a (pseudo) F or chi-square statistic which fails to consider the uncertainty of the smoothing parameter estimation.
</p>


<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>residuals </code></td>
<td>
<p>the deviance residuals.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fstatistic </code></td>
<td>
<p>the F statistic for testing all effects (parametric and smooth).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dev.expl </code></td>
<td>
<p>the explained deviance.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p.table </code></td>
<td>
<p>the coefficient table for (approximate) inference on the parametric terms.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>s.table </code></td>
<td>
<p>the coefficient table for (approximate) inference on the smooth terms.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dispersion </code></td>
<td>
<p>the estimate of the dispersion parameter.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>r.squared </code></td>
<td>
<p>the observed coefficient of multiple determination.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>adj.r.squared </code></td>
<td>
<p>the adjusted coefficient of multiple determination.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kappa </code></td>
<td>
<p>the collinearity indices, i.e., square-roots of the variance inflation factors (see <code>varinf</code>). A value of 1 indicates no collinearity, and higher values indicate more collinearity of a given term with other model terms.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pi </code></td>
<td>
<p>the importance indices. Larger values indicate more importance, and the values satisfy <code>sum(pi) = 1</code>. Note that elements of <code>pi</code> can be negative.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>call </code></td>
<td>
<p>the original function call.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>family </code></td>
<td>
<p>the specified family (for gsm objects).</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Helwig, N. E. (2020). Multiple and Generalized Nonparametric Regression. In P. Atkinson, S. Delamont, A. Cernat, J. W. Sakshaug, &amp; R. A. Williams (Eds.), <em>SAGE Research Methods Foundations.</em> <a href="https://doi.org/10.4135/9781526421036885885">doi:10.4135/9781526421036885885</a>
</p>
<p>Nychka, D. (1988). Bayesian confience intervals for smoothing splines. <em>Journal of the American Statistical Association, 83(404)</em>, 1134-1143. <a href="https://doi.org/10.2307/2290146">doi:10.2307/2290146</a>
</p>
<p>Wahba, G. (1983). Bayesian "confidence intervals" for the cross-validated smoothing spline. <em>Journal of the Royal Statistical Society. Series B, 45(1)</em>, 133-150. <a href="https://doi.org/10.1111/j.2517-6161.1983.tb01239.x">doi:10.1111/j.2517-6161.1983.tb01239.x</a>
</p>


<h3>See Also</h3>

<p><code>gsm</code>, <code>sm</code>, and <code>ss</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">### Example 1: gsm

# generate data
set.seed(1)
n &lt;- 1000
x &lt;- seq(0, 1, length.out = n)
z &lt;- factor(sample(letters[1:3], size = n, replace = TRUE))
fun &lt;- function(x, z){
  mu &lt;- c(-2, 0, 2)
  zi &lt;- as.integer(z)
  fx &lt;- mu[zi] + 3 * x + sin(2 * pi * x + mu[zi]*pi/4)
}
fx &lt;- fun(x, z)
y &lt;- rbinom(n = n, size = 1, p = 1 / (1 + exp(-fx)))

# define marginal knots
probs &lt;- seq(0, 0.9, by = 0.1)
knots &lt;- list(x = quantile(x, probs = probs),
              z = letters[1:3])

# fit sm with specified knots (tprk = TRUE)
gsm.ssa &lt;- gsm(y ~ x * z, family = binomial, knots = knots)
summary(gsm.ssa)

# fit sm with specified knots (tprk = FALSE)
gsm.gam &lt;- gsm(y ~ x * z, family = binomial, knots = knots, tprk = FALSE)
summary(gsm.gam)


### Example 2: sm

# generate data
set.seed(1)
n &lt;- 100
x &lt;- seq(0, 1, length.out = n)
z &lt;- factor(sample(letters[1:3], size = n, replace = TRUE))
fun &lt;- function(x, z){
  mu &lt;- c(-2, 0, 2)
  zi &lt;- as.integer(z)
  fx &lt;- mu[zi] + 3 * x + sin(2 * pi * x + mu[zi]*pi/4)
}
fx &lt;- fun(x, z)
y &lt;- fx + rnorm(n, sd = 0.5)

# define marginal knots
probs &lt;- seq(0, 0.9, by = 0.1)
knots &lt;- list(x = quantile(x, probs = probs),
              z = letters[1:3])

# fit sm with specified knots (tprk = TRUE)
sm.ssa &lt;- sm(y ~ x * z, knots = knots)
summary(sm.ssa)

# fit sm with specified knots (tprk = FALSE)
sm.gam &lt;- sm(y ~ x * z, knots = knots, tprk = FALSE)
summary(sm.gam)


### Example 3: ss

# generate data
set.seed(1)
n &lt;- 100
x &lt;- seq(0, 1, length.out = n)
fx &lt;- 2 + 3 * x + sin(2 * pi * x)
y &lt;- fx + rnorm(n, sd = 0.5)

# regular smoothing spline
ss.reg &lt;- ss(x, y, nknots = 10)
summary(ss.reg)

</code></pre>


</div>