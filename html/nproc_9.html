<div class="container">

<table style="width: 100%;"><tr>
<td>rocCV</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Calculate the Receiver Operating Characteristics with Cross-validation or Subsampling</h2>

<h3>Description</h3>

<p><code>rocCV</code> calculates the receiver operating characterisitc with cross-validation
</p>


<h3>Usage</h3>

<pre><code class="language-R">rocCV(x = NULL, y, method = c("logistic", "penlog", "svm", "randomforest",
  "lda", "nb", "ada", "tree"), metric = "CV", n.folds = 5,
  train.frac = 0.5, n.cores = 1, randSeed = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>n * p observation matrix. n observations, p covariates.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>n 0/1 observatons.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>classification method(s).
</p>

<ul>
<li>
<p> logistic: Logistic regression. glm function with family = 'binomial'
</p>
</li>
<li>
<p> penlog: Penalized logistic regression with LASSO penalty. <code>glmnet</code> in <code>glmnet</code> package
</p>
</li>
<li>
<p> svm: Support Vector Machines. <code>svm</code> in <code>e1071</code> package
</p>
</li>
<li>
<p> randomforest: Random Forest. <code>randomForest</code> in <code>randomForest</code> package
</p>
</li>
<li>
<p> Linear Discriminant Analysis. lda: <code>lda</code> in <code>MASS</code> package
</p>
</li>
<li>
<p> nb: Naive Bayes. <code>naiveBayes</code> in <code>e1071</code> package
</p>
</li>
<li>
<p> ada: Ada-Boost. <code>ada</code> in <code>ada</code> package
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>metric</code></td>
<td>
<p>metric used for averging performance. Includes 'CV' and 'SS' as options. Default = 'CV'.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.folds</code></td>
<td>
<p>number of folds used for cross-validation or the number of splits in the subsampling. Default = 5.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>train.frac</code></td>
<td>
<p>fraction of training data in the subsampling process. Default = 0.5.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.cores</code></td>
<td>
<p>number of cores used for parallel computing. Default = 1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>randSeed</code></td>
<td>
<p>the random seed used in the algorithm. Default = 0.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>additional arguments.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A list.
</p>
<table>
<tr style="vertical-align: top;">
<td><code>fpr</code></td>
<td>
<p>sequence of false positive rate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tpr</code></td>
<td>
<p>sequence of true positive rate.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Xin Tong, Yang Feng, and Jingyi Jessica Li (2018), Neyman-Pearson (NP) classification algorithms and NP receiver operating characteristic (NP-ROC), <em>Science Advances</em>, <b>4</b>, 2, eaao1659.
</p>


<h3>See Also</h3>

<p><code>nproc</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">n = 200
x = matrix(rnorm(n*2),n,2)
c = 1 - 3*x[,1]
y = rbinom(n,1,1/(1+exp(-c)))
fit = rocCV(x, y, method = 'svm')
fit2 = rocCV(x, y, method = 'penlog')
fit3 = rocCV(x, y, method = 'penlog', metric = 'SS')
</code></pre>


</div>