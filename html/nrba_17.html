<div class="container">

<table style="width: 100%;"><tr>
<td>t_test_by_response_status</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>t-test of differences in means/percentages between responding sample and full sample, or between responding sample and eligible sample</h2>

<h3>Description</h3>

<p>The function <code>t_test_resp_vs_full</code> tests whether means of auxiliary variables differ between respondents and the full selected sample,
where the full sample consists of all cases regardless of response status or eligibility status. <br>
The function <code>t_test_resp_vs_elig</code> tests whether means differ between the responding sample and the eligible sample,
where the eligible sample consists of all cases known to be eligible, regardless of response status.
</p>
<p>See Lohr and Riddles (2016) for the statistical theory of this test.
</p>


<h3>Usage</h3>

<pre><code class="language-R">t_test_resp_vs_full(
  survey_design,
  y_vars,
  na.rm = TRUE,
  status,
  status_codes = c("ER", "EN", "IE", "UE"),
  null_difference = 0,
  alternative = "unequal",
  degrees_of_freedom = survey::degf(survey_design) - 1
)

t_test_resp_vs_elig(
  survey_design,
  y_vars,
  na.rm = TRUE,
  status,
  status_codes = c("ER", "EN", "IE", "UE"),
  null_difference = 0,
  alternative = "unequal",
  degrees_of_freedom = survey::degf(survey_design) - 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>survey_design</code></td>
<td>
<p>A survey design object created with the <code>survey</code> package.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y_vars</code></td>
<td>
<p>Names of dependent variables for tests. For categorical variables, percentages of each category are tested.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.rm</code></td>
<td>
<p>Whether to drop cases with missing values for a given dependent variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>status</code></td>
<td>
<p>The name of the variable representing response/eligibility status. <br>
The <code>status</code> variable should have at most four categories,
representing eligible respondents (ER), eligible nonrespondents (EN),
known ineligible cases (IE), and cases whose eligibility is unknown (UE).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>status_codes</code></td>
<td>
<p>A named vector, with four entries named 'ER', 'EN', 'IE', and 'UE'. <br><code>status_codes</code> indicates how the values of the <code>status</code> variable are to be interpreted.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>null_difference</code></td>
<td>
<p>The difference between the two means under the null hypothesis. Default is <code>0</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alternative</code></td>
<td>
<p>Can be one of the following: <br></p>

<ul>
<li> <p><code>'unequal'</code> (the default): two-sided test of whether difference in means is equal to <code>null_difference</code> <br></p>
</li>
<li> <p><code>'less'</code>: one-sided test of whether difference is less than <code>null_difference</code> <br></p>
</li>
<li> <p><code>'greater'</code>: one-sided test of whether difference is greater than <code>null_difference</code>
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>degrees_of_freedom</code></td>
<td>
<p>The degrees of freedom to use for the test's reference distribution.
Unless specified otherwise, the default is the design degrees of freedom minus one,
where the design degrees of freedom are estimated using the <code>survey</code> package's <code>degf</code> method.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A data frame describing the results of the t-tests, one row per dependent variable.
</p>


<h3>Statistical Details</h3>

<p>The t-statistic used for the test has as its numerator the difference in means between the two samples, minus the <code>null_difference</code>.
The denominator for the t-statistic is the estimated standard error of the difference in means.
Because the two means are based on overlapping groups and thus have correlated sampling errors, special care is taken to estimate the covariance of the two estimates.
For designs which use sets of replicate weights for variance estimation, the two means and their difference are estimated using each set of replicate weights;
the estimated differences from the sets of replicate weights are then used to estimate sampling error with a formula appropriate to the replication method (JKn, BRR, etc.).
For designs which use linearization methods for variance estimation, the covariance between the two means is estimated using the method of linearization based on influence functions implemented in the <code>survey</code> package.
See Osier (2009) for an overview of the method of linearization based on influence functions.
Eckman et al. (2023) showed in a simulation study that linearization and replication
performed similarly in estimating the variance of a difference in means for overlapping samples. <br><br>
Unless specified otherwise using the <code>degrees_of_freedom</code> parameter, the degrees of freedom for the test are set to the design degrees of freedom minus one.
Design degrees of freedom are estimated using the <code>survey</code> package's <code>degf</code> method. <br><br>
See Lohr and Riddles (2016) for the statistical details of this test.
See Van de Kerckhove et al. (2009) and  Amaya and Presser (2017)
for examples of a nonresponse bias analysis which uses t-tests to compare responding samples to eligible samples.
</p>


<h3>References</h3>


<ul>
<li>
<p> Amaya, A., Presser, S. (2017). <em>Nonresponse Bias for Univariate and Multivariate Estimates of Social Activities and Roles</em>. Public Opinion Quarterly, Volume 81, Issue 1, 1 March 2017, Pages 1â€“36, https://doi.org/10.1093/poq/nfw037
</p>
</li>
<li>
<p> Eckman, S., Unangst, J., Dever, J., Antoun, A. (2023). <em>The Precision of Estimates of Nonresponse Bias in Means</em>. Journal of Survey Statistics and Methodology, 11(4), 758-783. https://doi.org/10.1093/jssam/smac019
</p>
</li>
<li>
<p> Lohr, S., Riddles, M. (2016). <em>Tests for Evaluating Nonresponse Bias in Surveys</em>. Survey Methodology 42(2): 195-218. https://www150.statcan.gc.ca/n1/pub/12-001-x/2016002/article/14677-eng.pdf
</p>
</li>
<li>
<p> Osier, G. (2009). <em>Variance estimation for complex indicators of poverty and inequality using linearization techniques</em>. Survey Research Methods, 3(3), 167-195. https://doi.org/10.18148/srm/2009.v3i3.369
</p>
</li>
<li>
<p> Van de Kerckhove, W., Krenzke, T., and Mohadjer, L. (2009). <em>Adult Literacy and Lifeskills Survey (ALL) 2003: U.S. Nonresponse Bias Analysis (NCES 2009-063)</em>. National Center for Education Statistics, Institute of Education Sciences, U.S. Department of Education. Washington, DC.
</p>
</li>
</ul>
<h3>Examples</h3>

<pre><code class="language-R">library(survey)

# Create a survey design ----
data(involvement_survey_srs, package = 'nrba')

survey_design &lt;- svydesign(weights = ~ BASE_WEIGHT,
                           id = ~ UNIQUE_ID,
                           fpc = ~ N_STUDENTS,
                           data = involvement_survey_srs)

# Compare respondents' mean to the full sample mean ----

t_test_resp_vs_full(survey_design = survey_design,
                    y_vars = c("STUDENT_AGE", "WHETHER_PARENT_AGREES"),
                    status = 'RESPONSE_STATUS',
                    status_codes = c('ER' = "Respondent",
                                     'EN' = "Nonrespondent",
                                     'IE' = "Ineligible",
                                     'UE' = "Unknown"))

# Compare respondents' mean to the mean of all eligible cases ----

t_test_resp_vs_full(survey_design = survey_design,
                    y_vars = c("STUDENT_AGE", "WHETHER_PARENT_AGREES"),
                    status = 'RESPONSE_STATUS',
                    status_codes = c('ER' = "Respondent",
                                     'EN' = "Nonrespondent",
                                     'IE' = "Ineligible",
                                     'UE' = "Unknown"))
# One-sided tests ----

  ## Null Hypothesis: Y_bar_resp - Y_bar_full &lt;= 0.1
  ## Alt. Hypothesis: Y_bar_resp - Y_bar_full &gt;  0.1

t_test_resp_vs_full(survey_design = survey_design,
                    y_vars = c("STUDENT_AGE", "WHETHER_PARENT_AGREES"),
                    status = 'RESPONSE_STATUS',
                    status_codes = c('ER' = "Respondent",
                                     'EN' = "Nonrespondent",
                                     'IE' = "Ineligible",
                                     'UE' = "Unknown"),
                    null_difference = 0.1, alternative = 'greater')

  ## Null Hypothesis: Y_bar_resp - Y_bar_full &gt;= 0.1
  ## Alt. Hypothesis: Y_bar_resp - Y_bar_full &lt;  0.1

t_test_resp_vs_full(survey_design = survey_design,
                    y_vars = c("STUDENT_AGE", "WHETHER_PARENT_AGREES"),
                    status = 'RESPONSE_STATUS',
                    status_codes = c('ER' = "Respondent",
                                     'EN' = "Nonrespondent",
                                     'IE' = "Ineligible",
                                     'UE' = "Unknown"),
                    null_difference = 0.1, alternative = 'less')
</code></pre>


</div>