<div class="container">

<table style="width: 100%;"><tr>
<td>nsga3fs</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>NSGA III for Multi-Objective Feature Selection</h2>

<h3>Description</h3>

<p>An adaptation of Non-dominated Sorting Genetic Algorithm III for multi
objective feature selection tasks.
Non-dominated Sorting Genetic Algorithm III is a genetic algorithm that solves multiple
optimization problems simultaneously by applying a non-dominated sorting
technique. It uses a reference points based selection operator to explore
solution space and preserve diversity. See the paper by K. Deb and
H. Jain (2014) &lt;DOI:10.1109/TEVC.2013.2281534&gt; for a detailed description of the algorithm.
</p>


<h3>Usage</h3>

<pre><code class="language-R">nsga3fs(df, target, obj_list, obj_names, pareto, pop_size, max_gen, model,
  resampling = FALSE, num_features = TRUE, mutation_rate = 0.1,
  threshold = 0.5, feature_cost = FALSE,
  r_measures = list(mlr::mmce), cpus = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>df</code></td>
<td>
<p>An original dataset.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>target</code></td>
<td>
<p>Name of a column (a string), which contains classification target variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>obj_list</code></td>
<td>
<p>A List of objective functions to be optimizied.
Must be a list of objects of type closure.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>obj_names</code></td>
<td>
<p>A Vector of the names of objective functions.
Must match the atguments passed to pareto.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pareto</code></td>
<td>
<p>A Pareto criteria for non-dominated sorting. Should be passed in a form:
<code class="reqn">low(objective_1)*high(objective_2)</code>
See description of <code>low</code> for more details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pop_size</code></td>
<td>
<p>Size of the population.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_gen</code></td>
<td>
<p>Number of generations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>A <code>makeLearner</code> object. A model to be used for
classification task.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>resampling</code></td>
<td>
<p>A <code>makeResampleDesc</code> object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num_features</code></td>
<td>
<p>TRUE if algorithm should minimize number of features as one of objectives.
You must pass a respective object to pareto as well as obj_names.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mutation_rate</code></td>
<td>
<p>Probability of switching the value of a certain gene to its opposite.
Default value 0.1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>threshold</code></td>
<td>
<p>Threshold applied during majority vote when calculating final output.
Default  value 0.5.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>feature_cost</code></td>
<td>
<p>A vector of feacure costs. Must be equal ncol(df)-1.
You must pass a respective object to pareto as well as obj_names.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>r_measures</code></td>
<td>
<p>A list of performance metrics for <code>makeResampleDesc</code> task.
Default "mmce"</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cpus</code></td>
<td>
<p>Number of sockets to be used for parallelisation. Default value is 1.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A list with the final Pareto Front:
</p>

<dl>
<dt>Raw</dt>
<dd>
<p>A list containing two items:
</p>

<ol>
<li>
<p> A list with final Pareto Front individuals
</p>
</li>
<li>
<p> A data.frame containing respective fitness values
</p>
</li>
</ol>
</dd>
<dt>Per individual</dt>
<dd>
<p>Same content, structured per individual</p>
</dd>
<dt>Majority vote</dt>
<dd>
<p>Pareto Front majority vote for dataset features</p>
</dd>
<dt>Stat</dt>
<dd>
<p>Runtime, dataset details, model</p>
</dd>
</dl>
<h3>Note</h3>

<p>Be cautious with setting the size of population and maximum generations.
Since NSGA III is a wrapper feature selection method, a model has to be retrained
N*number of generation +1 times, which may involve high computational costs.
A 100 x 100 setting should be enough.
</p>
<p>This adaptation of NSGA III algorithm for Multi Objective Feature Selection is currently
available only for classification tasks.
</p>
<p>#'As any other Genetic Algorithm (GA), NSGA III includes following steps:
</p>

<ol>
<li>
<p> An initial population Pt of a size N is created
</p>
</li>
<li>
<p> A model is trained on each individual (subset) and fitness values are assigned
</p>
</li>
<li>
<p> An offsping population of a size N is created by crossover and mutation operators
</p>
</li>
<li>
<p> The offspring population is combined with its parent population
</p>
</li>
<li>
<p> A combined population of a size 2N is split into Pareto Fronts using non-dominated
sorting technique
</p>
</li>
<li>
<p> A next generation's population Pt+1 of size N is selected from the top Pareto Fronts
with help of elitism based selection operator
</p>
</li>
</ol>
<p>The loop is repeated until the final generation is reached
</p>
<p>Each generation is populated by individuals representing different subsets.
Each individual is represented as a binary vector, where each gene represents
a feature in the original dataset.
</p>


<h3>References</h3>

<p>K. Deb, H. Jain (2014) &lt;DOI:10.1109/TEVC.2013.2281534&gt;
</p>


<h3>Examples</h3>

<pre><code class="language-R">xgb_learner &lt;- mlr::makeLearner("classif.xgboost", predict.type = "prob",
                            par.vals = list(
                            objective = "binary:logistic",
                            eval_metric = "error",nrounds = 2))

rsmp &lt;- mlr::makeResampleDesc("CV", iters = 2)
measures &lt;- list(mlr::mmce)

f_auc &lt;- function(pred){auc &lt;- mlr::performance(pred, auc)
                        return(as.numeric(auc))}
objective &lt;- c(f_auc)
o_names &lt;- c("AUC", "nf")
par &lt;- rPref::high(AUC)*rPref::low(nf)

nsga3fs(df = german_credit, target = "BAD", obj_list = objective,
        obj_names = o_names, pareto = par, pop_size = 1, max_gen = 1,
        model = xgb_learner, resampling = rsmp,
        num_features = TRUE, r_measures = measures, cpus = 2)





</code></pre>


</div>